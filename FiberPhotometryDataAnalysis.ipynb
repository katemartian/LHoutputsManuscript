{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FiberPhotometryDataAnalysis.ipynb","provenance":[],"collapsed_sections":["YUvJbtK5Qp5B","_uwClG3MSUEH","lTv0DQjOLQis","wHHD5Nsnl4Wj","Kjv9sM8fm0B9","6OpwwgDinYc6","cjVXjmTxQYH5","W6y1l6h6osL8","jYPC6PaLQOe7","EwS0b_QyRcVm","TxaRCTaDdNJi","J0DwnwPjRhm6","c4yCzfkIR0wC","9btxEByzR7CJ","PFg-9Jdk1gfv","0nn0JkXQ3I9P","m0PxBqtjUEDH","jj90oAZZyIux","UOLNC3luM0vL","9sMG8y21nSa3","Ohfbz2kSizL0","MmuLDF6J4yif","-buDFD0FPh3x","QIMMZUP3-RaN","QSym_oP31PBm","J0iJmpxgADbJ","gjAjg96synxw","GKC4oLOHPnYq","-U6jBI8Zpj64","DuyOMytDrCjz","q3k3WcshtEal"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"j3HPoSWJjO3a"},"source":["<h1><center>Fiber Photometry Data Analysis</center><h1>\n"]},{"cell_type":"markdown","metadata":{"id":"NFzvQojMRRrS"},"source":["The package was developed by Ekaterina Martianova during her PhD studies in Christophe Proulx lab at CERVO Brain Research Center at Laval University\n","\n","The package includes: \n","\n","- Functions necessary to process raw signals recorded with camera-based fiber photometry;\n","\n","- Helper functions to process behavior data recorded/created with behavior softwares, e.g. Med Associates, ANY-maze, DeepLabCut;\n","\n","- Helper functions to create summary plots."]},{"cell_type":"markdown","metadata":{"id":"LFp21ODJkgad"},"source":["# Import necessary libraries\n"]},{"cell_type":"code","metadata":{"id":"_-93AaITkx4R"},"source":["import os\n","import sys\n","import time \n","import pandas as pd\n","import numpy as np\n","np.random.seed(0)\n","import h5py\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from collections import OrderedDict\n","mpl.style.use('classic')\n","import seaborn as sns\n","from scipy.stats.stats import pearsonr\n","from scipy import signal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZ92TQo8CtBG"},"source":["# Show images only if asked \n","plt.ioff()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlbUCnNvJaZc"},"source":["# Recording Class\n"]},{"cell_type":"code","metadata":{"id":"zJUrCrf9Jd1T"},"source":["class FiberPhotometryRecording:\n","\n","  '''\n","    A class used to represent a Fiber Photometry Recording\n","    ...\n","\n","    Attributes\n","    ----------\n","    signals : dict\n","        Calcium-dependent traces recorded with 470 nm (e.g. GCaMP) or 560 nm (e.g. jrGECO) LEDs\n","    references : dict\n","        Calcium-independent traces recorded with 405-415 nm LED\n","    time_ : numpay.ndarray\n","        Timestamps of the recording\n","    events : dict\n","        External or behavioral events that happening during the recoring\n","    meaurements : dict\n","        Other continious recordings happening along with the fiber photometry recording\n","    mouse : str\n","        Name of a mouse\n","    test : str\n","        Name of a test\n","    trial : str\n","        Number of a trial\n","\n","    Methods\n","    -------\n","    loadRecording(filename,mouse,test,trial='1')\n","        Loads a recording from a specified filename file for specified mouse, test, and trial\n","    \n","    '''\n","\n","\n","  import h5py\n","  import numpy as np\n","  import pandas as pd\n","\n","  def __init__(self,signals=None,references=None,time_=None,\n","               events=None,measurements=None,mouse='mouse',test='test',trial='1'):\n","\n","    s = signals is None; r = references is None; t = time_ is None\n","    if (s^r or r^t or s^t):\n","      raise TypeError('To initialize the object, the function takes either 0 or 3-8 arguments (signals, references, time_, ...).')\n","\n","    if signals and references and time_ is not None:\n","      if (type(signals) or type(references)) is not dict:\n","        raise TypeError('signals and references have to be dictionaries with keys indicating names of neural populations and values indicating corresponding traces as 1D numpy.ndarray.')\n","\n","      if signals.keys() != references.keys():\n","        raise KeyError('Keys in signals and references dictionaries have to be the same.')\n","\n","      for output in signals:\n","        if (type(signals[output]) or type(references[output])) is not np.ndarray:\n","          raise TypeError('Values of signals and references dictionaries have to be 1D numpy.ndarray.')\n","        if signals[output].ndim != 1 or references[output].ndim != 1:\n","          raise ValueError('Values of signals and refernces dictionaries have to be 1D numpy.ndarray.')\n","\n","      if type(time_) is not np.ndarray:\n","        raise TypeError('time_ argument has to be 1D numpy.ndarray.')\n","      if time_.ndim != 1:\n","        raise ValueError('time_ argument has to be 1D numpy.ndarray.')\n","      \n","      for output in signals:\n","        if signals[output].size != time_.size or references[output].size != time_.size:\n","          raise ValueError('All signals, references, and time arrays have to be the same length.')\n","\n","      if events is not None:\n","        if type(events) is not dict:\n","          raise TypeError('events argument has to be a dictionary.')\n","        for e in events:\n","          if type(events[e]) is not np.ndarray:\n","            raise TypeError('Values of events dictionary have to be 2D numpy.ndarrays.')\n","          if events[e].ndim != 2:\n","            raise ValueError('Values of events dictionary have to be 2D numpy.ndarrays.')\n","\n","      if measurements is not None:\n","        if type(measurements) is not dict:\n","          raise TypeError('measurements argument has to be a dictionary.')\n","        for m in measurements:\n","          if type(measurements[m]) is not dict:\n","            raise TypeError('Values of measurements dictionary have to be dictionaries with keys \"time\" and \"values\".')\n","          keys = list(measurements[m].keys()); keys.sort()\n","          if keys != ['time', 'values']:\n","            raise TypeError('Values of measurements dictionary have to be dictionaries with keys \"time\" and \"values\".')\n","          if (type(measurements[m]['time']) or type(measurements[m]['values'])) is not np.ndarray:\n","            raise TypeError('Values of \"time\" and \"values\" in measurements dictionary have to be 1D numpy.ndarray.')\n","          if measurements[m]['time'].ndim != 1 or measurements[m]['values'].ndim != 1:\n","            raise ValueError('Values of \"time\" and \"values\" in measurements dictionary have to be 1D numpy.ndarray.')\n","          if measurements[m]['time'].size != measurements[m]['values'].size:\n","            raise ValueError('Arrays of \"time\" and \"values\" in measurements dictionary have to be the same length.')\n","\n","        if type(mouse) is not str:\n","          raise TypeError('Argument mouse has to be a string.')\n","        if type(test) is not str:\n","          raise TypeError('Argument test has to be a string.')\n","        if type(trial) is not str:\n","          raise TypeError('Argument test has to be a string.')\n","\n","          \n","    self.rawSignals = signals\n","    self.rawReferences = references\n","    self.signals = None\n","    self.references = None\n","    self.dFFs = None\n","    self.time = time_\n","    self.events = events\n","    self.measurements = measurements\n","    self.perievents = None\n","    self.measurePerievents = None\n","    self.mouse = mouse\n","    self.test = test\n","    self.trial = trial\n","\n","    if self.rawSignals is not None:\n","      self.outputs = list(self.rawSignals.keys())\n","    else:\n","      self.outputs = None\n","\n","    if time_ is not None:\n","      self.period = find_avg_period(self.time)\n","      self.frequency = 1 / self.period\n","    else:\n","      self.period = None\n","      self.frequency = None\n","\n","    self.timeDFF = None\n","    \n","\n","\n","  def __repr__(self):\n","    if self.outputs is None:\n","      self = None\n","      return 'No recording was loaded.'\n","\n","    outputs_string = ''\n","    for output in self.outputs:\n","      outputs_string += output + ', '\n","    return 'Fiber photometry recordings for mouse {} in outputs/pathways {}during test {}-{}.'\\\n","            .format(self.mouse,outputs_string,self.test,self.trial)\n","\n","\n","\n","  def saveRecording(self,fileHDF):\n","\n","    with h5py.File(fileHDF, 'a') as f:\n","\n","     # Raw\n","      for output in self.outputs:    \n","        path = 'Raw/'+self.test+'/'+output+'/'+self.mouse+'/'+self.trial+'/'\n","        saveToHDF(f,path+'time',self.time)\n","        saveToHDF(f,path+'signal',self.rawSignals[output])\n","        saveToHDF(f,path+'reference',self.rawReferences[output])\n","\n","     # Recordings   \n","      if self.signals is not None:\n","        for output in self.outputs:    \n","          path = 'Recordings/'+self.test+'/'+output+'/'+self.mouse+'/'+self.trial+'/'\n","          saveToHDF(f,path+'time',self.time)\n","          saveToHDF(f,path+'signal',self.signals[output])\n","          saveToHDF(f,path+'reference',self.references[output])\n","\n","     # dF/F\n","      if self.dFFs is not None:\n","        for output in self.outputs:    \n","          path = 'DFFs/'+self.test+'/'+output+'/'+self.mouse+'/'+self.trial+'/'\n","          saveToHDF(f,path+'dFF',self.dFFs[output])\n","          if self.timeDFF is not None:\n","            saveToHDF(f,path+'time',self.timeDFF)\n","          else: \n","            saveToHDF(f,path+'time',self.time)\n","\n","     # Events\n","      if self.events is not None:\n","        for event in self.events.keys():\n","          path = 'Events/'+self.test+'/'+event+'/'+self.mouse+'/'+self.trial+'/'\n","          saveToHDF(f,path+'timestamps',self.events[event])\n","\n","     # Measurements\n","      if self.measurements is not None:\n","        for measure in self.measurements.keys():\n","          path = 'Measurements/'+self.test+'/'+measure+'/'+self.mouse+'/'+self.trial+'/'\n","          saveToHDF(f,path+'values',self.measurements[measure]['values'])\n","          saveToHDF(f,path+'time',self.measurements[measure]['time'])\n","\n","     # Perievents\n","      if self.perievents is not None:\n","        for output in self.perievents:\n","          for event in self.perievents[output]:\n","            for onoffset in self.perievents[output][event]:\n","              path = 'Perievents/'+self.test+'/'+output+'/'+event+'/'+onoffset+'/'+self.mouse+'/'+self.trial\n","              saveToHDF(f,path,self.perievents[output][event][onoffset])\n","\n","     # MeasurePerievents\n","      if self.measurePerievents is not None:\n","        for measure in self.measurePerievents:\n","          for event in self.measurePerievents[measure]:\n","            for onoffset in self.measurePerievents[measure][event]:\n","              path = 'MeasurePerievents/'+self.test+'/'+measure+'/'+event+'/'+onoffset+'/'+self.mouse+'/'+self.trial\n","              saveToHDF(f,path,self.measurePerievents[measure][event][onoffset])\n","\n","\n","\n","  def removeRecording(self,fileHDF,remove='processed'):\n","\n","    '''\n","    remove: 'all', 'processed'\n","            ['raw','events','measures','signal','dFF','perievents','measurePerievents']\n","    '''\n","\n","    if remove=='all':\n","      remove = ['raw','events','measures','signal','dFF','perievents','measurePerievents']\n","    if remove=='processed':\n","      remove = ['signal','dFF','perievents','measurePerievents']\n","\n","    with h5py.File(fileHDF, 'a') as f:\n","\n","      if 'raw' in remove:\n","        if self.rawSignals is not None:\n","          for output in self.outputs:\n","            path = 'Raw/'+self.test+'/'+output+'/'+self.mouse+'/'+self.trial+'/'\n","            try:\n","              del f[path+'signal']\n","              del f[path+'reference']\n","              del f[path+'time']\n","            except KeyError:\n","              return print('The recording is not saved in the file.')\n","\n","      if 'events' in remove:\n","        if self.events is not None:\n","          for event in self.events:\n","            path = 'Events/'+self.test+'/'+event+'/'+self.mouse+'/'+self.trial+'/'\n","            del f[path+'timestamps']\n","\n","      if 'measurements' in remove:\n","        if self.measurements is not None:\n","          for measure in self.measurements:\n","            path = 'Measurements/'+self.test+'/'+measure+'/'+self.mouse+'/'+self.trial+'/'\n","            del f[path+'values']\n","            del f[path+'time']\n","\n","      if 'signal' in remove:\n","        if self.signals is not None:\n","          for output in self.outputs:\n","            path = 'Recordings/'+self.test+'/'+output+'/'+self.mouse+'/'+self.trial+'/'\n","            del f[path+'time']\n","            del f[path+'signal']\n","            del f[path+'reference']\n","\n","      if 'dFF' in remove:\n","        if self.dFFs is not None:\n","          for output in self.outputs:\n","            path = 'DFFs/'+self.test+'/'+output+'/'+self.mouse+'/'+self.trial+'/'\n","            del f[path+'dFF']\n","            del f[path+'time']\n","\n","      if 'perievents' in remove:\n","        if self.perievents is not None:\n","          for output in self.perievents:\n","            for event in self.perievents[output]:\n","              for onoffset in self.perievents[output][event]:\n","                path = 'Perievents/'+self.test+'/'+output+'/'+event+'/'+onoffset+'/'+self.mouse+'/'+self.trial\n","                del f[path]\n","\n","      if 'measurePerievents' in remove:\n","        if self.measurePerievents is not None:\n","          for measure in self.measurePerievents:\n","            for event in self.measurePerievents[measure]:\n","              for onoffset in self.measurePerievents[measure][event]:\n","                path = 'MeasurePerievents/'+self.test+'/'+measure+'/'+event+'/'+onoffset+'/'+self.mouse+'/'+self.trial\n","                del f[path]\n","\n","\n","\n","  \n","  def loadRecording(self,fileHDF,mouse,test,trial='1'):\n","        \n","    self.mouse = mouse\n","    self.test = test\n","    self.trial = trial\n","\n","    with h5py.File(fileHDF, 'r') as f:\n","\n","      if 'Raw/'+test in f:\n","        outputs = list(f['Raw/'+test].keys())\n","      else:\n","        return print('No recordings are saved for test {}.'.format(test))\n","\n","      self.rawSignals = {}\n","      self.rawReferences = {}\n","      for output in outputs:\n","        path = 'Raw/'+test+'/'+output+'/'+mouse+'/'+trial+'/'\n","        if path in f:\n","          self.rawSignals[output] = np.array(f[path].get('signal'))\n","          self.rawReferences[output] = np.array(f[path].get('reference'))\n","          self.time = np.array(f[path].get('time'))\n","      if self.rawSignals == {}:\n","        self.mouse = None\n","        self.test = None\n","        self.trial = None\n","        self.rawSignals = None\n","        self.rawReferences = None\n","        return 'The recording for animal {} in the experiment {}-{} is not saved in the file.'.format(mouse,test,trial)\n","        \n","      self.outputs = list(self.rawSignals.keys())\n","\n","      self.period = find_avg_period(self.time)\n","      self.frequency = 1 / self.period\n","      \n","      if 'Recordings/'+self.test in f:\n","        self.signals = {}\n","        self.references = {}\n","        for output in self.outputs:\n","          path = 'Recordings/'+test+'/'+output+'/'+mouse+'/'+trial+'/'\n","          if path in f:\n","            self.signals[output] = np.array(f[path].get('signal'))\n","            self.references[output] = np.array(f[path].get('reference'))\n","\n","      if 'DFFs/'+test in f:\n","        self.dFFs = {}\n","        for output in outputs:\n","          path = 'DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/'\n","          if path in f:\n","            self.dFFs[output] = np.array(f[path].get('dFF'))\n","            self.timeDFF = np.array(f[path].get('time'))\n","\n","      if 'Events/'+test in f:\n","        self.events = {}\n","        for event in f['Events/'+test]:\n","          path = 'Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/'\n","          if path in f:\n","            self.events[event] = np.array(f[path].get('timestamps'))\n","\n","      if 'Measurements/'+test in f:    \n","        self.measurements = {}\n","        for measure in f['Measurements/'+test]:\n","          path = 'Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/'\n","          if path in f:\n","            self.measurements[measure] = {'time': np.array(f[path].get('time')),\n","                                        'values': np.array(f[path].get('values'))}\n","         \n","      if 'Perievents/'+test in f:\n","        self.perievents = {}\n","        for output in f['Perievents/'+test]:\n","          self.perievents[output] = {}\n","          for event in f['Perievents/'+test+'/'+output]:\n","            self.perievents[output][event] = {}\n","            for onoffset in f['Perievents/'+test+'/'+output+'/'+event]:\n","              path = 'Perievents/'+test+'/'+output+'/'+event+'/'+onoffset+'/'+mouse\n","              if path+'/'+trial in f:\n","                self.perievents[output][event][onoffset] = np.array(f[path].get(trial))\n","              else:\n","                self.perievents = {}\n","                break\n","            else:\n","              continue # continue if the inner loop wasn't broken\n","            break      # break if the inner loop was broken\n","\n","\n","      if 'MeasurePerievents/'+test in f:\n","        self.measurePerievents = {}\n","        for measure in f['MeasurePerievents/'+test]:\n","          self.measurePerievents[measure] = {}\n","          for event in f['MeasurePerievents/'+test+'/'+measure]:\n","            self.measurePerievents[measure][event] = {}\n","            for onoffset in f['MeasurePerievents/'+test+'/'+measure+'/'+event]:\n","              path = 'MeasurePerievents/'+test+'/'+measure+'/'+event+'/'+onoffset+'/'+mouse\n","              if path+'/'+trial in f:\n","                self.measurePerievents[measure][event][onoffset] = np.array(f[path].get(trial))\n","              else:\n","                self.measurePerievents = {}\n","                break\n","            else:\n","              continue\n","            break\n","\n","    return print('The recording for mouse {} in the experiment {}-{} is successfully loaded.'.format(mouse,test,trial))\n","\n","\n","\n","\n","\n","  def getDFF(self,\n","            smooth=True,smooth_filter='low-pass',smooth_parameter=1,\n","            remove_slope=True,airpls_lambda=1e4,absolute_intensities=False,\n","            remove_beginning=True,remove=10,\n","            standardize=True,\n","            model='Lasso',\n","            interpolate=False,period=0.1,\n","            plot=False,figsize=(20,13),save=False,image_format='.pdf'):\n","\n","    self.preprocess(smooth,smooth_filter,smooth_parameter,\n","                    remove_slope,airpls_lambda,absolute_intensities,\n","                    remove_beginning,remove,standardize,\n","                    plot,figsize,save,image_format)\n","\n","    self.align(model,plot,figsize,save,image_format)\n","\n","    self.calculateDFF(standardize,plot,figsize,save,image_format)\n","\n","    if interpolate:\n","      self.interpolateDFF(period)\n","\n","    plt.close('all')\n","\n","\n","\n","\n","  def getPerievents(self,info_for_array=None,\n","                    plot=False,save=False,image_format='.pdf'):\n","    \n","    if self.timeDFF is not None:\n","      time_ = self.timeDFF\n","    else:\n","      time_ = self.time\n","\n","   # Adjust events   \n","   # Remove events that are at the beginning of dF/F where are NANs\n","    dFF = self.dFFs[list(self.dFFs.keys())[0]]    \n","    idx = np.max(np.argwhere(np.isnan(dFF))) + 1\n","    events = self.events\n","    for event in events:\n","      e = events[event]\n","      if e.size != 0:\n","        events[event] = e[np.all(e > time_[idx], axis=1)]\n","    \n","    self.perievents = {}\n","    for output in self.outputs:\n","      self.perievents[output] = {}\n","\n","    if self.measurements is not None:\n","      self.measurePerievents = {}\n","      for measure in self.measurements:\n","        m = self.measurements[measure]['values']\n","        if not isbinary(m):\n","          self.measurePerievents[measure] = {}\n","\n","    period = find_avg_period(time_)\n","\n","    cmap = get_cmap(len(self.events))\n","\n","    for k,event in enumerate(self.events):\n","\n","      if self.events[event].size != 0:\n","\n","        try:\n","          window = info_for_array[event]['window']\n","        except:\n","          window = [-5.0,5.0]\n","        try: \n","          dur = info_for_array[event]['duration']\n","        except:\n","          dur = None\n","        try:\n","          iei = info_for_array[event]['interval']\n","        except:\n","          iei = None\n","        try:    \n","          avg_win = info_for_array[event]['avg_frame']\n","        except:\n","          avg_win = None\n","        try:    \n","          figsize = info_for_array[event]['figsize']\n","        except:\n","          figsize = None  \n","\n","        for output in self.dFFs:\n","          Array = create_perievents(self.dFFs[output],time_,events[event],\n","                                  window,dur,iei,avg_win)\n","          self.perievents[output][event] = Array\n","            \n","        if self.measurements is not None:\n","          for measure in self.measurements:\n","            measure_values = self.measurements[measure]['values']\n","            measure_time = self.measurements[measure]['time']\n","            if not isbinary(measure_values):\n","              Array1 = create_perievents(measure_values,measure_time,events[event],\n","                                        window,dur,iei)\n","              self.measurePerievents[measure][event] = Array1\n","            \n","      # Plot if asked \n","        if plot:\n","          \n","          plt.close('all')\n","\n","          if save:\n","            create_folder('./figures')\n","            create_folder('./figures/5_mean')\n","          for output in self.outputs:\n","            Array = self.perievents[output][event]\n","            if self.measurePerievents is not None:\n","              for measure in self.measurePerievents:\n","                Array1 = self.measurePerievents[measure][event]\n","                period1 = find_avg_period(self.measurements[measure]['time'])\n","                figtitle = self.mouse + ' ' + output + ' ' + self.test + \\\n","                          self.trial + ' ' + event + ' ' + measure\n","                plot_perievents(Array,period,Array1,period1,\n","                                window,cmap(k),figtitle,figsize,\n","                                save,'./figures/5_mean/',image_format)\n","            else:\n","              figtitle = self.mouse + ' ' + output + ' ' + self.test + self.trial + ' ' + event \n","              plot_perievents(Array,period,window=window,\n","                              color=cmap(k),figtitle=figtitle,figsize=figsize,\n","                              save=save,save_path='./figures/5_mean/',\n","                              image_format=image_format)\n","          \n","    plt.close('all')      \n","\n","\n","\n","  # def preprocess(self,smooth_filter='low-pass',smooth_win=1,\n","  #                flatten=True,airpls_lambda=1e4,airpls_itermax=50,abs_int=False,\n","  #                remove=30,standardize=True,\n","  #                plot=False,figsize=(24,13),save=False,image_format='.pdf'):\n","  \n","  #   for i,t in enumerate(self.time):\n","  #     if t > remove:\n","  #       i0 = i-1\n","  #       break\n","\n","  #   self.signals = {}\n","  #   self.references = {}\n","\n","  # # Itterate through different outputs\n","  #   for output in self.outputs:\n","\n","  #     s = self.rawSignals[output].copy()\n","  #     r = self.rawReferences[output].copy()\n","\n","  #    # Smooth \n","  #     if smooth_filter=='moving average':\n","  #       s = smooth_signal(s,window_len=smooth_win/self.period)\n","  #       r = smooth_signal(r,window_len=smooth_win/self.period)\n","\n","  #     elif smooth_filter=='low-pass':\n","  #       cutoff = 1 / smooth_win\n","  #       f = int(round(self.frequency))\n","  #       s = butter_lowpass_filter(s, cutoff, f, order=5)\n","  #       r = butter_lowpass_filter(r, cutoff, f, order=5)\n","\n","  #    # Flatten\n","  #     if flatten: \n","  #       s, s_base = flatten_signal(s,lambda_=airpls_lambda,itermax=airpls_itermax)\n","  #       r, r_base = flatten_signal(r,lambda_=airpls_lambda,itermax=airpls_itermax)\n","        \n","  #       if abs_int:\n","  #         s = s + min(s_base)\n","  #         r = r + min(r_base)\n","        \n","\n","  #    # Remove the begining\n","  #     r[:i0] = np.nan\n","  #     s[:i0] = np.nan\n","\n","\n","  #    # Standardize signal to mean 0 and std 1\n","  #     if standardize:\n","  #       s = standardize_signal(s)\n","  #       r = standardize_signal(r)\n","\n","\n","  #     self.signals[output] = s\n","  #     self.references[output] = r\n","\n","\n","  #    # Plot if asked\n","  #     if plot:\n","  #       plt.close('all')\n","\n","  #       figtitle = self.mouse + ' ' + output + ' ' + self.test + self.trial\n","\n","  #       if save:\n","  #         create_folder('figures')\n","  #         create_folder('figures/1_raw')\n","\n","  #       plot_raw(self.rawSignals[output],self.rawReferences[output],s,r,s_base,r_base,self.time,\n","  #               self.events,self.measurements,\n","  #               figtitle,figsize,save,'./figures/1_raw/',image_format)\n","        \n","  def preprocess(self,\n","                 smooth=True,smooth_filter='low-pass',smooth_parameter=1,\n","                 remove_slope=True,airpls_lambda=1e4,absolute_intensities=False,\n","                 remove_beginning=True,remove=10,\n","                 standardize=True,\n","                 plot=False,figsize=(24,13),\n","                 save=False,image_format='.pdf'):\n","  \n","    self.signals = self.rawSignals.copy()\n","    self.references = self.rawReferences.copy()\n","\n","   # Smooth\n","    if smooth:\n","      self.smooth(smooth_filter,smooth_parameter)\n","\n","   # Remove the slope\n","    if remove_slope:\n","      s_slope,r_slope = self.removeSlope(airpls_lambda,absolute_intensities)\n","\n","   # Remove the begining\n","    if remove_beginning:\n","      self.removeBeginning(remove)\n","\n","   # Standardize signal to mean 0 and std 1\n","    if standardize:\n","      self.standardize()\n","\n","            \n","   # Plot and save if needed\n","    if save:\n","      create_folder('figures')\n","      create_folder('figures/1_raw')\n","\n","    if plot:\n","      for output in self.outputs:  \n","        \n","        figtitle = self.mouse + ' ' + output + ' ' + self.test + self.trial\n","\n","        plot_raw(self.rawSignals[output],self.rawReferences[output],\n","                self.signals[output],self.references[output],\n","                s_slope[output],r_slope[output],\n","                self.time,self.events,self.measurements,\n","                figtitle,figsize,save,'./figures/1_raw/',image_format)\n","\n","\n","  def smooth(self, smooth_filter='low-pass',smooth_parameter=1,take_raw=False):\n","        \n","    if smooth_filter not in ['low-pass','moving average']:\n","      raise TypeError('Argument smooth_filter can be only \"low-pass\" or \"moving average\".')\n","\n","    if take_raw or self.signals is None:\n","      self.signals = self.rawSignals.copy()\n","      self.references = self.rawReferences.copy()\n","\n","    for output in self.outputs:\n","\n","      s = self.signals[output].copy()\n","      r = self.references[output].copy()\n","\n","     # Smooth \n","      if smooth_filter=='moving average':\n","        s = smooth_signal(s,window_len=int(smooth_parameter/self.period))\n","        r = smooth_signal(r,window_len=int(smooth_parameter/self.period))\n","\n","      elif smooth_filter=='low-pass':\n","        cutoff = smooth_parameter\n","        f = int(round(self.frequency))\n","        s = butter_lowpass_filter(s, cutoff, f, order=5)\n","        r = butter_lowpass_filter(r, cutoff, f, order=5)  \n","\n","      self.signals[output] = s\n","      self.references[output] = r\n","\n","\n","  def removeSlope(self, airpls_lambda=1e4,absolute_intensities=False,take_raw=False):\n","\n","    if take_raw or self.signals is None:\n","      self.signals = self.rawSignals.copy()\n","      self.references = self.rawReferences.copy()\n","\n","    s_slope = {}\n","    r_slope = {}\n","\n","    for output in self.outputs:\n","\n","      s = self.signals[output].copy()\n","      r = self.references[output].copy()\n","\n","      s, s_slope[output] = flatten_signal(s,lambda_=airpls_lambda)\n","      r, r_slope[output] = flatten_signal(r,lambda_=airpls_lambda)\n","        \n","      if absolute_intensities:\n","        s = s + min(s_slope)\n","        r = r + min(r_slope)\n","\n","      self.signals[output] = s\n","      self.references[output] = r\n","\n","    return s_slope,r_slope\n","\n","\n","  def removeBeginning(self, remove=10,take_raw=False):\n","\n","    if take_raw or self.signals is None:\n","      self.signals = self.rawSignals.copy()\n","      self.references = self.rawReferences.copy()\n","\n","    for i,t in enumerate(self.time):\n","      if t > remove:\n","        i0 = i-1\n","        break\n","\n","    for output in self.outputs:\n","        \n","      self.signals[output][:i0] = np.nan\n","      self.references[output][:i0] = np.nan\n","\n","           \n","\n","  def standardize(self, take_raw=False):\n","\n","    if take_raw or self.signals is None:\n","      self.signals = self.rawSignals.copy()\n","      self.references = self.rawReferences.copy()\n","  \n","    for output in self.outputs:\n","\n","      self.signals[output] = standardize_signal(self.signals[output])\n","      self.references[output] = standardize_signal(self.references[output])\n","\n","\n","\n","\n","  def align(self, model='Lasso',\n","            plot=False,figsize=(24,13),\n","            save=False,image_format='.pdf'):\n","\n","    for output in self.outputs:\n","\n","      r_fitted = fit_signal(self.signals[output],self.references[output],model)\n","\n","      if plot:\n","        plt.close('all')\n","\n","        figtitle = self.mouse + ' ' + output + ' ' + self.test + self.trial\n","\n","        if save:\n","          create_folder('figures')\n","          create_folder('figures/2_fit')\n","          create_folder('figures/3_align')\n","\n","        plot_fit(self.signals[output],self.references[output],r_fitted,\n","                figtitle,(15,13),save,'./figures/2_fit/',image_format)\n","        plot_aligned(self.signals[output],r_fitted,self.time,self.events,self.measurements,\n","                    figtitle,figsize,save,'./figures/3_align/',image_format)\n","    \n","      self.references[output] = r_fitted\n","\n","\n","\n","\n","  def calculateDFF(self,standardized=True,\n","                   plot=False,figsize=(24, 13),save=False,image_format='.pdf'):\n","    \n","    self.dFFs = {}\n","\n","    for output in self.outputs:\n"," \n","      self.dFFs[output] = calculate_dff(self.signals[output],self.references[output])\n","\n","      if plot:\n","        plt.close('all')\n","\n","        figtitle = self.mouse + ' ' + output + ' ' + self.test + self.trial\n","\n","        if save:\n","          create_folder('figures')\n","          create_folder('figures/4_dFF')\n","        \n","        plot_dff(self.dFFs[output],self.time,self.events,self.measurements,\n","                figtitle,figsize,save,'./figures/4_dFF/',image_format)\n","\n","\n","\n","  def interpolateDFF(self,period=0.1):\n","\n","    time_ = self.time\n","\n","    for output in self.outputs:\n","\n","      signal = self.dFFs[output]\n","\n","      i_nans = np.argwhere(np.isnan(signal))\n","      if i_nans.size != 0:\n","        i0 = np.max(i_nans) + 1\n","        t_nans = np.arange(0,time_[i0],period)\n","        t0 = np.max(t_nans) + period\n","        t1 = np.max(time_)\n","        t_new = np.arange(t0,t1,period)\n","        intrp_signal = interpolate_signal(signal[i0:],time_[i0:],t_new)\n","        nans = np.empty((len(t_nans),))\n","        nans[:] = np.nan\n","        new_signal = np.r_[nans,intrp_signal]\n","        new_time = np.r_[t_nans,t_new]\n","      else:\n","        t_new = np.arrange(0,time[-1],period)\n","        signal = interpolate_signal(signal,time_,t_new)\n","\n","      self.dFFs[output] = new_signal\n","      self.timeDFF = new_time\n","\n","\n","  def smoothMeasurements(self,smooth_filter='low-pass',smooth_parameter=1):\n","\n","    for measure in self.measurements:\n","      if not isbinary(self.measurements[measure]['values']):\n","\n","        m = self.measurements[measure]['values']\n","        t = self.measurements[measure]['time']\n","\n","        T = find_avg_period(t)\n","\n","        i_nans = np.argwhere(np.isnan(m))\n","        if i_nans.size != 0:\n","          i0 = np.max(i_nans) + 1\n","          m = m[i0:]\n","          nans = m[:i0]\n","\n","      \n","        if smooth_filter=='moving average':\n","          m = smooth_signal( m, window_len=int(round(smooth_parameter/T)) )\n","\n","        elif smooth_filter=='low-pass':\n","          cutoff = smooth_parameter\n","          f = 1 / T\n","          m = butter_lowpass_filter(m, cutoff, f, order=10)\n","\n","\n","        if i_nans.size != 0:\n","          m = np.r_[nans,m]\n","\n","        self.measurements[measure]['values'] = m\n","\n","\n","\n","\n","  def interpolateMeasurements(self,period=0.1):\n","\n","    for measure in self.measurements:\n","      if not isbinary(self.measurements[measure]['values']):\n","\n","        signal = self.measurements[measure]['values']\n","        time_ = self.measurements[measure]['time']\n","\n","        if time_[0] < 0:\n","          i0 = np.max(np.argwhere(time_<0))\n","          signal = signal[i0:]\n","          time_ = time_[i0:]\n","\n","        i_nans = np.argwhere(np.isnan(signal))\n","        if i_nans.size != 0:\n","          i0 = np.max(i_nans) + 1\n","          t_nans = np.arange(0,time_[i0],period)\n","          t0 = np.max(t_nans) + period\n","          t1 = np.max(time_)\n","          t_new = np.arange(t0,t1,period)\n","          intrp_signal = interpolate_signal(signal[i0:],time_[i0:],t_new)\n","          nans = np.empty((len(t_nans),))\n","          nans[:] = np.nan\n","          new_signal = np.r_[nans,intrp_signal]\n","          new_time = np.r_[t_nans,t_new]\n","        else:\n","          if time_[0] > 0:\n","            t_nans = np.arange(0,time_[0]+period,period)\n","            t0 = np.max(t_nans) + period\n","            t1 = np.max(time_)\n","            t_new = np.arange(t0,t1,period)\n","            intrp_signal = interpolate_signal(signal,time_,t_new)\n","            nans = np.empty((len(t_nans),))\n","            nans[:] = np.nan\n","            new_signal = np.r_[nans,intrp_signal]\n","            new_time = np.r_[t_nans,t_new]\n","          else:\n","            new_time = np.arange(0,time_[-1],period)\n","            new_signal = interpolate_signal(signal,time_,new_time)\n","\n","        self.measurements[measure]['values'] = new_signal\n","        self.measurements[measure]['time'] = new_time\n","\n","\n","\n","\n","  def plotExample(self,outputs,event=None,measure=None,t0=0,t1=90,**kwargs):\n","\n","    if self.timeDFF is not None:\n","      time_ = self.timeDFF\n","    else:\n","      time_ = self.time\n","\n","    i0 = find_idx(t0,time_)\n","    i1 = find_idx(t1,time_)\n","\n","    time_ = time_[i0:i1] - t0\n","\n","    dFF1 = None\n","    dFF2 = None\n","    for i,output in enumerate(outputs):\n","      if i==0:\n","        dFF = self.dFFs[output][i0:i1]\n","      elif i==1:\n","        dFF1 = self.dFFs[output][i0:i1]\n","      elif i==2:\n","        dFF2 = self.dFFs[output][i0:i1]\n","\n","    events = None\n","    if event is not None:\n","      events = self.events[event]\n","      events = events[np.all(events > t0, axis=1)]\n","      events = events[np.all(events < t1, axis=1)]\n","      events = events - t0\n","\n","    measurement = None\n","    time_m = None\n","    if measure is not None:\n","      measurement = self.measurements[measure]['values']\n","      time_m = self.measurements[measure]['time']\n","\n","      j0 = find_idx(t0,time_m)\n","      j1 = find_idx(t1,time_m)\n","\n","      measurement = measurement[j0:j1]\n","      time_m = time_m[j0:j1]\n","\n","  \n","    plot_example(dFF,time_,events,dFF1,dFF2,measurement,time_m,**kwargs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YUvJbtK5Qp5B"},"source":["# Test Class"]},{"cell_type":"code","metadata":{"id":"VRIt6jAVQu3D"},"source":["class FiberPhotometryTest:\n","  def __init__(self,filename,test):\n","    self.filename = filename\n","    self.test = test\n","    with h5py.File(filename,'r') as f:\n","\n","      if 'Raw/'+test not in f:\n","        return print('Data for test {} is not saved in the file.'.format(test))\n","\n","      try:\n","        self.mice = list(f.attrs['mice'])\n","        self.outputs = list(f.attrs['outputs'])\n","        if f.attrs['good recordings'].size != 0:\n","          self.goodRecordings = [list(line) for line in list(f.attrs['good recordings']) if test in line]\n","        else:\n","          self.goodRecordings = []\n","        print('Experiment information for test {} is successfully loaded.'.format(test))\n","      except:\n","        print('Set names of mice, outputs/pathways recorded and good recordings\\nas attributes of HDF file, and create the object again')\n","\n","\n","\n","  def removeExperiment(self,remove='processed'):\n","\n","    '''\n","    remove: 'all', 'processed\n","            ['Raw','Events','Measurements','Recordings','DFFs','Perievents','MeasurePerievents',\n","             'Means','MeasureMeans','MeasureCorrelation','OutputCorrelation',\n","             'MeasurePerieventCorrelation','OutputPerieventCorrelation']\n","    '''\n","\n","    if remove=='all':\n","      remove = ['Raw','Events','Measurements','Recordings','DFFs','Perievents','MeasurePerievents',\n","                'Means','MeasureMeans','MeasureCorrelation','OutputCorrelation',\n","                'MeasurePerieventCorrelation','OutputPerieventCorrelation']\n","\n","    if remove=='processed':\n","      remove = ['Recordings','DFFs','Perievents','MeasurePerievents',\n","                'Means','MeasureMeans','MeasureCorrelation','OutputCorrelation',\n","                'MeasurePerieventCorrelation','OutputPerieventCorrelation']\n","\n","\n","    with h5py.File(self.filename, 'a') as f:\n","\n","      if 'Raw' in remove:\n","        if 'Raw/'+self.test in f:\n","          del f['Raw/'+self.test]\n","\n","      if 'Events' in remove:\n","        if 'Events/'+self.test in f:  \n","          del f['Events/'+self.test]\n","\n","      if 'Measurements' in remove:    \n","        if 'Measurements/'+self.test in f:  \n","          del f['Measurements/'+self.test]\n","\n","      if 'Recordings' in remove:\n","        if 'Recordings/'+self.test in f:\n","          del f['Recordings/'+self.test]\n","\n","      if 'DFFs' in remove:\n","        if 'DFFs/'+self.test in f:\n","          del f['DFFs/'+self.test]\n","\n","      if 'Perievents' in remove:\n","        if 'Perievents/'+self.test in f:\n","          del f['Perievents/'+self.test]\n","\n","      if 'MeasurePerievents' in remove:\n","        if 'MeasurePerievents/'+self.test in f:\n","          del f['MeasurePerievents/'+self.test]\n","\n","      if 'Means' in remove:\n","        if 'Means/'+self.test in f:\n","          del f['Means/'+self.test]\n","\n","      if 'MeasureMeans' in remove:\n","        if 'MeasureMeans/'+self.test in f:\n","          del f['MeasureMeans/'+self.test]\n","\n","      if 'MeasureCorrelation' in remove:\n","        if 'MeasureCorrelation/'+self.test in f:\n","          del f['MeasureCorrelation/'+self.test]\n","\n","      if 'OutputCorrelation' in remove:\n","        if 'OutputCorrelation/'+self.test in f:\n","          del f['OutputCorrelation/'+self.test]\n","\n","      if 'MeasurePerieventCorrelation' in remove:\n","        if 'MeasurePerieventCorrelation/events/'+self.test in f:\n","          del f['MeasurePerieventCorrelation/events/'+self.test]\n","          del f['MeasurePerieventCorrelation/correlation/'+self.test]\n","          del f['MeasurePerieventCorrelation/counts/'+self.test]\n","        \n","      if 'OutputPerieventCorrelation' in remove:\n","        if 'OutputPerieventCorrelation/events/'+self.test in f:\n","          del f['OutputPerieventCorrelation/events/'+self.test]\n","          del f['OutputPerieventCorrelation/correlation/'+self.test]\n","          del f['OutputPerieventCorrelation/counts/'+self.test]\n","        \n","    print('The data is successfully removed from the file {}.'.format(self.filename))\n","\n","    return\n","\n","  \n","      \n","\n","\n","  def getMeans(self,period=None,perievent_windows=None,auc_frames=None):\n","\n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","\n","      if 'Perievents/'+test not in f:\n","        return print('Perievents were not created.')\n","\n","      for output in f['Perievents/'+test]:\n","        for event in f['Perievents/'+test+'/'+output]: \n","          for onoffset in f['Perievents/'+test+'/'+output+'/'+event]:\n","\n","            means = []\n","            mice = []\n","            mice_periods = []\n","            for mouse in f['Perievents/'+test+'/'+output+'/'+event+'/'+onoffset]:\n","\n","              mouse_perievents = []\n","              mouse_periods = []\n","              for trial in f['Perievents/'+test+'/'+output+'/'+event+'/'+onoffset+'/'+mouse]:\n","\n","                if self.goodRecordings != []:\n","                  if [mouse, test, trial, output] in self.goodRecordings:\n","\n","                    print(mouse+','+trial, end=' ')\n","                            \n","                    time_ = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                    trial_period = find_avg_period(time_)\n","                    mouse_periods.append(trial_period)\n","                    trial_perievents = list(f['Perievents/'+test+'/'+output+'/'+event+'/'+onoffset+'/'+mouse+'/'+trial])\n","                    mouse_perievents.extend(trial_perievents)\n","\n","                else:\n","\n","                  print(mouse+','+trial, end=' ')\n","                          \n","                  time_ = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                  trial_period = find_avg_period(time_)\n","                  mouse_periods.append(trial_period)\n","                  trial_perievents = list(f['Perievents/'+test+'/'+output+'/'+event+'/'+onoffset+'/'+mouse+'/'+trial])\n","                  mouse_perievents.extend(trial_perievents)\n","\n","              if mouse_perievents != []: \n","                mouse_perievents = np.array(mouse_perievents).squeeze()\n","                if len(mouse_perievents.shape) == 1:\n","                  mouse_perievents = mouse_perievents.reshape(1,len(mouse_perievents))\n","                means.append(np.mean(mouse_perievents,axis=0))\n","                mice.append(mouse)\n","                mice_periods.append(np.mean(mouse_periods))\n","\n","            means = np.array(means).squeeze()\n","\n","            if len(means.shape) == 1:\n","              means = means.reshape(1,len(means))\n","\n","            if means.size != 0:\n","            # Calculate AUC \n","              try:\n","                window = perievent_windows[event+'-'+onoffset]\n","              except:\n","                window = [-5,5]\n","              try:\n","                time_frames = auc_frames[event+'-'+onoffset]\n","              except:\n","                time_frames = [[-2,-1],[1,2]]\n","              experiment_period = np.mean(mice_periods)\n","              auc = calculate_auc(means,experiment_period,window,time_frames)\n","\n","            # Save\n","              meansPath = 'Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/'\n","              saveToHDF(f,meansPath+'means',means)\n","              saveToHDF(f,meansPath+'auc',auc)\n","              saveToHDF(f,meansPath+'mice',np.array(mice,dtype=h5py.string_dtype(encoding='utf-8')))\n","              saveToHDF(f,meansPath+'periods',mice_periods)\n","\n","              print('.')\n","              print('Saved dF/F mean traces for {} {}-{}'.format(output,event,onoffset))\n","            \n","            else:\n","              print('Empty dF/F mean traces for {} {}-{}.'.format(output,event,onoffset))\n","\n","      if 'MeasurePerievents/'+test in f:\n","\n","        for measure in f['MeasurePerievents/'+test]:\n","          for event in f['MeasurePerievents/'+test+'/'+measure]: \n","            for onoffset in f['MeasurePerievents/'+test+'/'+measure+'/'+event]:\n","\n","              means = []\n","              mice = []\n","              mice_periods = []\n","              for mouse in f['MeasurePerievents/'+test+'/'+measure+'/'+event+'/'+onoffset]:\n","\n","                mouse_perievents = []\n","                mouse_periods = []\n","                for trial in f['MeasurePerievents/'+test+'/'+measure+'/'+event+'/'+onoffset+'/'+mouse]:\n","                  print(mouse+','+trial,end=' ')\n","                            \n","                  time_ = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","                  trial_period = find_avg_period(time_)\n","                  mouse_periods.append(trial_period)\n","                  trial_perievents = list(f['MeasurePerievents/'+test+'/'+measure+'/'+event+'/'+onoffset+'/'+mouse+'/'+trial])\n","                  mouse_perievents.extend(trial_perievents)\n","\n","                if mouse_perievents != []:\n","                  mouse_perievents = np.array(mouse_perievents).squeeze()\n","                  if len(mouse_perievents.shape) == 1:\n","                    mouse_perievents = mouse_perievents.reshape(1,len(mouse_perievents))\n","                  means.append(np.mean(mouse_perievents,axis=0))\n","                  mice.append(mouse)\n","                  mice_periods.append(np.mean(mouse_periods))\n","\n","              means = np.array(means).squeeze()\n","\n","              if len(means.shape) == 1:\n","                means = means.reshape(1,len(means))\n","\n","              if means.size != 0:\n","              # Calculate AUC\n","                try:\n","                  window = perievent_windows[event+'-'+onoffset]\n","                except:\n","                  window = [-5,5]\n","                try:\n","                  time_frames = auc_frames[event+'-'+onoffset]\n","                except:\n","                  time_frames = [[-2,-1],[ 1, 2]]\n","                experiment_period = np.mean(mice_periods)\n","                auc = calculate_auc(means,experiment_period,window,time_frames)\n","\n","              # Save\n","                meansPath = 'MeasureMeans/'+test+'/'+measure+'/'+event+'/'+onoffset+'/'\n","                saveToHDF(f,meansPath+'means',means)\n","                saveToHDF(f,meansPath+'auc',auc)\n","                saveToHDF(f,meansPath+'mice',np.array(mice,dtype=h5py.string_dtype(encoding='utf-8')))\n","                saveToHDF(f,meansPath+'periods',mice_periods)\n","\n","                print('.')\n","                print('Saved dF/F mean traces for {} {}-{}.'.format(measure,event,onoffset))\n","\n","              else:\n","                print('Empty measure mean trace for {} {}-{}.'.format(measure,event,onoffset))\n","\n","\n","\n","  def plotMeans(self,output,event,onoffset='onset',output2=None,measure=None,**kwargs):\n","\n","    test = self.test\n","\n","    if (output2 is not None) and (measure is not None):\n","      print('Choose to plot 2 different outups/paths or 1 output/path and 1 measure.')\n","      return\n","\n","    with h5py.File(self.filename, 'r') as f:\n","      \n","      if output == 'all':\n","        means = []\n","        auc = []\n","        mice = []\n","        Ts = []\n","        for output in f['Means/'+test]:\n","          means.extend(list(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/means']))\n","          auc.extend(list(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/auc']))\n","          mice.extend(list(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/mice']))\n","          Ts.extend(list(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/periods']))\n","        means = np.array(means).squeeze()\n","        auc = np.array(auc).squeeze()\n","        mice = np.array(mice).squeeze()\n","        T = np.mean(Ts)\n","      else:   \n","        means = np.array(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/means'])\n","        auc = np.array(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/auc'])\n","        mice = list(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/mice'])\n","        T = np.mean(f['Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/periods'])\n","      if output2 is not None:\n","        means1 = np.array(f['Means/'+test+'/'+output2+'/'+event+'/'+onoffset+'/means'])\n","        auc1 = np.array(f['Means/'+test+'/'+output2+'/'+event+'/'+onoffset+'/auc'])\n","        T1 = np.mean(f['Means/'+test+'/'+output2+'/'+event+'/'+onoffset+'/periods'])\n","      elif measure is not None:\n","        means1 = np.array(f['MeasureMeans/'+test+'/'+measure+'/'+event+'/'+onoffset+'/means'])\n","        auc1 = np.array(f['MeasureMeans/'+test+'/'+measure+'/'+event+'/'+onoffset+'/auc'])\n","        mice1 = list(f['MeasureMeans/'+test+'/'+measure+'/'+event+'/'+onoffset+'/mice'])\n","        T1 = np.mean(f['MeasureMeans/'+test+'/'+measure+'/'+event+'/'+onoffset+'/periods'])\n","        idx = [i for i in range(len(mice1)) if mice1[i] in mice]\n","        means1 = means1[idx,:]\n","        auc1 = auc1[idx,:]\n","      else:\n","        means1 = None\n","        auc1 = None\n","        T1 = None\n","\n","    plot_means(array=means,T=T,auc=auc,array1=means1,T1=T1,auc1=auc1,**kwargs)\n","\n","    return               \n","\n","\n","\n","\n","\n","  def getDataFrameAUC(self,event,onoffset,periods=['baseline','event'],\n","                      save=False,csvname='auc.csv'):\n","\n","    test = self.test\n","\n","    mice_list = []\n","    output_list = []\n","    period_list = []\n","    auc_list = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for output in f['Means/'+test]:\n","\n","        path = 'Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/'\n","        mice = list(f[path+'mice'])\n","        auc = np.array(f[path+'auc'])\n","\n","        for i,period in enumerate(periods):\n","\n","          n = len(mice)\n","          mice_list.extend(mice)\n","          output_list.extend([output]*n)\n","          period_list.extend([period]*n)\n","          auc_list.extend(list(auc[:,i]))\n","\n","\n","      df = pd.DataFrame({'mouse': mice_list,\n","                        'output': output_list,\n","                        'period': period_list,\n","                           'auc': auc_list})\n","      \n","      if save:\n","        df.to_csv(csvname,index=False)\n","\n","    return df\n","\n","\n","  def getDataFrameAUCmeasure(self,event,onoffset,periods=['baseline','event'],\n","                            save=False,csvname='auc.csv'):\n","\n","    test = self.test\n","\n","    mice_list = []\n","    measure_list = []\n","    period_list = []\n","    auc_list = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for measure in f['MeasureMeans/'+test]:\n","\n","        path = 'MeasureMeans/'+test+'/'+measure+'/'+event+'/'+onoffset+'/'\n","        mice = list(f[path+'mice'])\n","        auc = np.array(f[path+'auc'])\n","\n","        for i,period in enumerate(periods):\n","\n","          n = len(mice)\n","          mice_list.extend(mice)\n","          measure_list.extend([measure]*n)\n","          period_list.extend([period]*n)\n","          auc_list.extend(list(auc[:,i]))\n","\n","\n","      df = pd.DataFrame({'mouse': mice_list,\n","                       'measure': measure_list,\n","                        'period': period_list,\n","                           'auc': auc_list})\n","      \n","      if save:\n","        df.to_csv(csvname,index=False)\n","\n","    return df\n","\n","\n","\n","\n","  def getOutputCorrelation(self,output,output1):\n","      \n","    from scipy.stats import pearsonr\n","    from scipy.signal import resample\n","\n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","\n","      for output in f['DFFs/'+test]:\n","\n","        Rs = []\n","        ps = []\n","        mice = []\n","\n","        for mouse in f['DFFs/'+test+'/'+output]:\n","\n","          mouse_Rs = []\n","          mouse_ps = []\n","\n","          for trial in f['DFFs/'+test+'/'+output+'/'+mouse]:\n","\n","            if self.goodRecordings != []:\n","              if ([mouse,test,trial,output] in self.goodRecordings) and ([mouse,test,trial,output1] in self.goodRecordings):\n","\n","                print(mouse+','+trial, end=' ')\n","\n","                signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                signal1 = np.array(f['DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF'])\n","\n","                i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","\n","                trial_R,trial_p = pearsonr(signal[i0:],signal1[i0:])\n","\n","                mouse_Rs.append(trial_R)\n","                mouse_ps.append(trial_p)\n","\n","            else:\n","\n","              if 'DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF' in f:\n","\n","                print(mouse+','+trial, end=' ')\n","                            \n","                signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                signal1 = np.array(f['DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF'])\n","\n","                i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","\n","                trial_R,trial_p = pearsonr(signal[i0:],signal1[i0:])\n","\n","                mouse_Rs.append(trial_R)\n","                mouse_ps.append(trial_p)\n","\n","          if mouse_Rs != []:\n","            mice.append(mouse)\n","            Rs.append(np.mean(mouse_Rs))\n","            ps.append(np.mean(mouse_ps))\n","\n","      # Save\n","        #print('R:',Rs)\n","        #print('p:',ps)\n","        path = 'OutputCorrelation/'+test+'/'+output+'_'+output1+'/'\n","        saveToHDF(f,path+'R',Rs)\n","        saveToHDF(f,path+'pvalue',ps)\n","        saveToHDF(f,path+'mice',np.array(mice,dtype=h5py.string_dtype(encoding='utf-8')))\n","\n","        print('.')\n","        print('Saved pearson correlation R and p values between outputs {} and {}.'.format(output,output1 ))\n","\n","\n","\n","\n","  def getMeasureCorrelation(self,measure,new_period=0.1):\n","\n","    from scipy.stats import pearsonr\n","    from scipy.signal import resample\n","\n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","\n","      for output in f['DFFs/'+test]:\n","\n","        Rs = []\n","        ps = []\n","        mice = []\n","\n","        for mouse in f['DFFs/'+test+'/'+output]:\n","\n","          mouse_Rs = []\n","          mouse_ps = []\n","\n","          for trial in f['DFFs/'+test+'/'+output+'/'+mouse]:\n","\n","            if self.goodRecordings != []:\n","              if [mouse, test, trial, output] in self.goodRecordings:\n","\n","                print(mouse+','+trial, end=' ')\n","        \n","                time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","\n","                time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","                measurement = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/values'])\n","\n","                i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","\n","                if not np.array_equal(time_s[:5],time_m[:5]):\n","                  return print('Interpolate signals.')\n","\n","                if time_s[-1] < time_m[-1]:\n","                  i1 = len(time_s) - 1\n","                else:\n","                  i1 = len(time_m) - 1\n","\n","                trial_R,trial_p = pearsonr(signal[i0:i1],measurement[i0:i1])\n","\n","                mouse_Rs.append(trial_R)\n","                mouse_ps.append(trial_p)\n","\n","            else:\n","\n","              print(mouse+','+trial, end=' ')\n","                          \n","              time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","              signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","\n","              time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","              measurement = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/values'])\n","\n","              i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","\n","              if not np.array_equal(time_s[:5],time_m[:5]):\n","                return print('Interpolate signals.')\n","\n","              if time_s[-1] < time_m[-1]:\n","                i1 = len(time_s) - 1\n","              else:\n","                i1 = len(time_m) - 1\n","\n","              trial_R,trial_p = pearsonr(signal[i0:i1],measurement[i0:i1])\n","\n","              mouse_Rs.append(trial_R)\n","              mouse_ps.append(trial_p)\n","\n","          if mouse_Rs != []:\n","            mice.append(mouse)\n","            Rs.append(np.mean(mouse_Rs))\n","            ps.append(np.mean(mouse_ps))\n","\n","      # Save\n","        #print('R:',Rs)\n","        #print('p:',ps)\n","        path = 'MeasureCorrelation/'+test+'/'+measure+'/'+output+'/'\n","        saveToHDF(f,path+'R',Rs)\n","        saveToHDF(f,path+'pvalue',ps)\n","        saveToHDF(f,path+'mice',np.array(mice,dtype=h5py.string_dtype(encoding='utf-8')))\n","\n","        print('.')\n","        print('Saved pearson correlation R and p values for output {} and measurement {}.'.format(output,measure))\n","\n","\n","\n","\n","  def getOutputPerieventCorrelation(self,output,output1,event,other_events='inbetween',\n","                                    win=1,min_duration=2,min_interval=2):\n","    \n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","       \n","      if isinstance(event,list):\n","\n","        for mouse in f['Events/'+test+'/'+event[0]]:\n","          for trial in f['Events/'+test+'/'+event[0]+'/'+mouse]:\n","\n","            if 'DFFs/'+test+'/'+output+'/'+mouse+'/'+trial in f:\n","              dFF = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","              time_ = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","              period = find_avg_period(time_)\n","\n","            # Find where not NaN part of dFF starts \n","              i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","              t0 = time_[i0]+2*win\n","              t1 = time_[-1]-2*win\n","\n","              timestamps1 = np.array(f['Events/'+test+'/'+event[0]+'/'+mouse+'/'+trial+'/timestamps'])\n","              if len(timestamps1) != 0:\n","              # Remove events that fall to NaN part of dFF\n","                on_off_1 = timestamps1[np.all(timestamps1 > t0, axis=1)]\n","                on_off_1 = on_off_1[np.all(on_off_1 < t1, axis=1)]\n","              # Adjust timestamps to time vector\n","                inds1 = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off_1]\n","                on_off_1 = [ [time_[i],time_[j]] for i,j in inds1]\n","                on_off_1 = np.array(on_off_1)\n","              # Off event time\n","                off_on_1 = np.zeros(on_off_1.shape)\n","                off_on_1[0,0] = t0\n","                off_on_1[1:,0] = on_off_1[:-1,1]\n","                off_on_1[:,1] = on_off_1[:,0]\n","              # Onsets and offset\n","                on_1 = np.array(on_off_1[:,0])\n","                off_1 = np.array(on_off_1[:,1])\n","              # Adjust off time\n","                off_on_1 = adjust_intervals_durations(off_on_1,min_duration=2*win)\n","              else:\n","                on_1 = []\n","                off_1 = []\n","                off_on_1 = []\n","              \n","\n","              timestamps2 = np.array(f['Events/'+test+'/'+event[1]+'/'+mouse+'/'+trial+'/timestamps'])\n","              if len(timestamps2) != 0:\n","              # Remove events that fall to NaN part of dFF\n","                on_off_2 = timestamps2[np.all(timestamps2 > t0, axis=1)]\n","                on_off_2 = on_off_2[np.all(on_off_2 < t1, axis=1)]\n","              # Adjust timestamps to time vector\n","                inds2 = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off_2]\n","                on_off_2 = [ [time_[i],time_[j]] for i,j in inds2]\n","                on_off_2 = np.array(on_off_2)\n","              # Off event time\n","                off_on_2 = np.zeros(on_off_2.shape)\n","                off_on_2[0,0] = t0\n","                off_on_2[1:,0] = on_off_2[:-1,1]\n","                off_on_2[:,1] = on_off_2[:,0]\n","              # Onsets and offsets\n","                on_2 = np.array(on_off_2[:,0])\n","                off_2 = np.array(on_off_2[:,1])\n","              # Adjust off time\n","                off_on_2 = adjust_intervals_durations(off_on_2,min_duration=2*win)\n","              else:\n","                on_2 = []\n","                off_2 = []\n","                off_on_2 = []\n","            \n","            # Combine two off event times\n","              if len(off_on_1) == 0:\n","                off_on = off_on_2\n","              elif len(off_on_2) == 0:\n","                off_on = off_on_1\n","              else:\n","                off_on = np.concatenate((off_on_1,off_on_2),axis=0)\n","\n","            # Get random timestamps in off event time\n","              other = []\n","              for i,j in off_on:\n","                other.extend(np.arange(i+win,j-win+period,period))\n","\n","              # Choose subset of 50 events\n","              other = np.array(random_subset(other, 50))\n","\n","              path = 'OutputPerieventCorrelation/events/'+test+'/'+event[0]+'-'+event[1]+'/'\n","              saveToHDF(f,path+event[0]+'-onset/'+mouse+'/'+trial,on_1)\n","              saveToHDF(f,path+event[0]+'-offset/'+mouse+'/'+trial,off_1)\n","              saveToHDF(f,path+event[1]+'-onset/'+mouse+'/'+trial,on_2)\n","              saveToHDF(f,path+event[1]+'-offset/'+mouse+'/'+trial,off_2)\n","              saveToHDF(f,path+'other/'+mouse+'/'+trial,other)\n","\n","          event = event[0]+'-'+event[1]\n","\n","      else:\n","\n","       # Choose events\n","        for mouse in f['Events/'+test+'/'+event]:\n","          for trial in f['Events/'+test+'/'+event+'/'+mouse]:\n","\n","            if 'DFFs/'+test+'/'+output+'/'+mouse+'/'+trial in f:\n","              dFF = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","              time_ = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","              period = find_avg_period(time_)\n","                \n","              timestamps = np.array(f['Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/timestamps'])\n","\n","              if len(timestamps) == 0:\n","                continue\n","\n","              if timestamps.shape[1]==1:\n","\n","              # Find where not NaN part of dFF starts \n","                i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","                t0 = time_[i0]+win\n","                t1 = time_[-1]-win\n","\n","              # Remove events that fall to NaN part of dFF\n","                on = timestamps[np.all(timestamps > t0, axis=1)]\n","                on = on[np.all(on < t1, axis=1)]\n","\n","              # Adjust timestamps to time vector\n","                inds = [ find_idx(i,time_) for i in on]\n","                on = [ time_[i] for i in inds]\n","                on = np.array(on)\n","\n","                inbetween = [t0] + list(on) + [t1]\n","                other = []\n","                for i in range(len(inbetween)-1):\n","                  other.extend(np.arange(inbetween[i]+win,inbetween[i+1]-win+period,period))\n","\n","              # Choose subset of 50 events\n","                other = np.array(random_subset(other, 50))\n","\n","                path = 'OutputPerieventCorrelation/events/'+test+'/'+event+'/'\n","                saveToHDF(f,path+event+'/'+mouse+'/'+trial,on)\n","                saveToHDF(f,path+'other/'+mouse+'/'+trial,other)\n","\n","              else:\n","                if other_events == 'other':\n","\n","                # Find where not NaN part of dFF starts \n","                  i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","                  t0 = time_[i0]+2*win\n","                  t1 = time_[-1]-2*win\n","\n","                # Remove events that fall to NaN part of dFF\n","                  on_off = timestamps[np.all(timestamps > t0, axis=1)]\n","                  on_off = on_off[np.all(on_off < t1, axis=1)]\n","\n","                # Adjust timestamps to time vector\n","                  inds = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off]\n","                  on_off = [ [time_[i],time_[j]] for i,j in inds]\n","                  on_off = np.array(on_off)\n","\n","                  off_on = np.zeros(on_off.shape)\n","                  off_on[0,0] = t0\n","                  off_on[1:,0] = on_off[:-1,1]\n","                  off_on[:,1] = on_off[:,0]\n","\n","                  on = np.array(on_off[:,0])\n","                  off = np.array(on_off[:,1])\n","\n","                  off_on = adjust_intervals_durations(off_on,min_duration=2*win)\n","\n","                  other = []\n","                  for i,j in off_on:\n","                    other.extend(np.arange(i+win,j-win+period,period))\n","\n","                # Choose subset of 50 events\n","                  other = np.array(random_subset(other, 50))\n","\n","                  path = 'OutputPerieventCorrelation/events/'+test+'/'+event+'/'\n","                  saveToHDF(f,path+'onset/'+mouse+'/'+trial,on)\n","                  saveToHDF(f,path+'offset/'+mouse+'/'+trial,off)\n","                  saveToHDF(f,path+'other/'+mouse+'/'+trial,other)\n","\n","                elif other_events == 'inbetween':\n","\n","                # Find where not NaN part of dFF starts \n","                  i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","                  t0 = time_[i0]+2*win\n","                  t1 = time_[-1]-2*win\n","\n","                # Remove events that fall to NaN part of dFF\n","                  on_off = timestamps[np.all(timestamps > t0, axis=1)]\n","                  on_off = on_off[np.all(on_off < t1,  axis=1)]\n","\n","                # Adjust timestamps to time vector\n","                  inds = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off]\n","                  on_off = [ [time_[i],time_[j]] for i,j in inds]\n","                  on_off = np.array(on_off)\n","\n","                  off_on = np.zeros(on_off.shape)\n","                  off_on[0,0] = t0\n","                  off_on[1:,0] = on_off[:-1,1]\n","                  off_on[:,1] = on_off[:,0]\n","\n","                  onoffsets = adjust_intervals_durations(on_off,min_duration,min_interval)\n","                  on = np.array(onoffsets[:,0])\n","                  off = np.array(onoffsets[:,1])\n","\n","                  on_off = adjust_intervals_durations(on_off,min_duration=2*win)\n","                  off_on = adjust_intervals_durations(off_on,min_duration=2*win)\n","\n","                  dur_on_off = []\n","                  for i,j in on_off:\n","                    dur_on_off.extend(np.arange(i+win,j-win+period,period))\n","                  dur_off_on = []\n","                  for i,j in off_on:\n","                    dur_off_on.extend(np.arange(i+win,j-win+period,period))\n","\n","                # Choose subset of 50 events\n","                  dur_on_off = np.array(random_subset(dur_on_off, 50))\n","                  dur_off_on = np.array(random_subset(dur_off_on, 50))\n","\n","                  path = 'OutputPerieventCorrelation/events/'+test+'/'+event+'/'\n","                  saveToHDF(f,path+'onset/'+mouse+'/'+trial,on)\n","                  saveToHDF(f,path+'on-off/'+mouse+'/'+trial,dur_on_off)\n","                  saveToHDF(f,path+'offset/'+mouse+'/'+trial,off)\n","                  saveToHDF(f,path+'off-on/'+mouse+'/'+trial,dur_off_on)\n","\n","     # Calculate perievent correlation\n","      for mouse in f['DFFs/'+test+'/'+output]:\n","\n","        for e_part in f['OutputPerieventCorrelation/events/'+test+'/'+event]:\n","\n","          lags = []\n","          corrs = []\n","          maxlags = []\n","          maxcorrs = []\n","          Rs = []\n","          ps = []\n","\n","          for trial in f['DFFs/'+test+'/'+output+'/'+mouse]:\n","\n","            if self.goodRecordings != []:\n","              if ([mouse,test,trial,output] in self.goodRecordings) and ([mouse,test,trial,output1] in self.goodRecordings):\n","\n","                signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                signal1 = np.array(f['DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF'])\n","                time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                T_s = find_avg_period(time_s)\n","\n","                timestamps = np.array(f['OutputPerieventCorrelation/events/'+test+'/'+event+'/'+e_part+'/'+mouse+'/'+trial])\n","\n","                if len(timestamps) != 0:\n","                  for t in timestamps:\n","\n","                    idx = find_idx(t,time_s)\n","                    w = int(round(win/T_s))\n","\n","                    s = signal[idx-w:idx+w+1]\n","                    s1 = signal1[idx-w:idx+w+1]\n","\n","                    lag, corr = xcorr(s,s1,True,True,maxlags=w)\n","                    idx_maxlag = np.argmax(np.abs(corr))\n","                    maxcorr = corr[idx_maxlag]\n","                    maxlag = lag[idx_maxlag]\n","\n","                    s = signal[idx+maxlag-w:idx+maxlag+w+1]\n","\n","                    R,p = pearsonr(s,s1)\n","\n","                    lag = [i*T_s for i in lag]\n","                    maxlag = maxlag*T_s\n","\n","                    lags.append(lag)\n","                    corrs.append(corr)\n","                    maxlags.append(maxlag)\n","                    maxcorrs.append(maxcorr)\n","                    Rs.append(R)\n","                    ps.append(p)\n","\n","                path = 'OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'+mouse\n","                saveToHDF(f,path+'/lag',lags)\n","                saveToHDF(f,path+'/corr',corrs)\n","                #saveToHDF(f,path+'/max-lag',maxlags)\n","                #saveToHDF(f,path+'/max-corr',maxcorrs)\n","                saveToHDF(f,path+'/R',Rs)\n","                saveToHDF(f,path+'/pvalue',ps)\n","\n","            else:\n","                \n","              signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","              signal1 = np.array(f['DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF'])\n","              time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","              T_s = find_avg_period(time_s)\n","\n","              timestamps = np.array(f['OutputPerieventCorrelation/events/'+test+'/'+event+'/'+e_part+'/'+mouse+'/'+trial])\n","\n","              if len(timestamps) != 0:\n","                for t in timestamps:\n","\n","                  idx = find_idx(t,time_s)\n","                  w = int(round(win/T_s))\n","\n","                  s = signal[idx-w:idx+w+1]\n","                  s1 = signal1[idx-w:idx+w+1]\n","\n","                  lag, corr = xcorr(s,s1,True,True,maxlags=w)\n","                  idx_maxlag = np.argmax(np.abs(corr))\n","                  maxcorr = corr[idx_maxlag]\n","                  maxlag = lag[idx_maxlag]\n","\n","                  s = signal[idx+maxlag-w:idx+maxlag+w+1]\n","\n","                  R,p = pearsonr(s,s1)\n","\n","                  lag = [i*T_s for i in lag]\n","                  maxlag = maxlag*T_s\n","\n","                  lags.append(lag)\n","                  corrs.append(corr)\n","                  maxlags.append(maxlag)\n","                  maxcorrs.append(maxcorr)\n","                  Rs.append(R)\n","                  ps.append(p)\n","\n","              path = 'OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'+mouse\n","              saveToHDF(f,path+'/lag',lags)\n","              saveToHDF(f,path+'/corr',corrs)\n","              #saveToHDF(f,path+'/max-lag',maxlags)\n","              #saveToHDF(f,path+'/max-corr',maxcorrs)\n","              saveToHDF(f,path+'/R',Rs)\n","              saveToHDF(f,path+'/pvalue',ps)\n","\n","\n","     # Count positive/negative/not correlations \n","      for e_part in f['OutputPerieventCorrelation/correlation/'+test+'/'+event]:\n","\n","          mice = []\n","          list_not_corr = []\n","          list_pos_corr = []\n","          list_neg_corr = []\n","\n","          for mouse in f['OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1]:\n","            \n","            ps = np.array(f['OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'+mouse+'/pvalue'])\n","            Rs = np.array(f['OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'+mouse+'/R'])\n","\n","            if len(ps) != 0:\n","              n = len(ps)                               # total number events\n","              corr = Rs[(ps<0.001) & (np.abs(Rs)>0.6)]  # list of correlated events\n","              not_corr = (n - len(corr)) / n            # % of not correlated event\n","              pos_corr = sum(corr>0) / n                # % of positive correlated\n","              neg_corr = sum(corr<0) / n                # % of negative correlated\n","\n","              mice.append(mouse)\n","              list_not_corr.append(not_corr)\n","              list_pos_corr.append(pos_corr)\n","              list_neg_corr.append(neg_corr)\n","\n","          path = 'OutputPerieventCorrelation/counts/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1\n","          saveToHDF(f,path+'/mice',np.array(mice,dtype=h5py.string_dtype(encoding='utf-8')))\n","          saveToHDF(f,path+'/not-corr',list_not_corr)\n","          saveToHDF(f,path+'/pos-corr',list_pos_corr)\n","          saveToHDF(f,path+'/neg-corr',list_neg_corr)\n","\n","\n","\n","\n","  def getMeasurePerieventCorrelation(self,event,measure,other_events='inbetween',win=1,\n","                                     min_duration=2,min_interval=2):\n","    \n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","       \n","      if isinstance(event,list):\n","\n","        for mouse in f['Events/'+test+'/'+event[0]]:\n","          for trial in f['Events/'+test+'/'+event[0]+'/'+mouse]:\n","\n","            outputs = list(f['DFFs/'+test])\n","            for output in outputs:\n","              if 'DFFs/'+test+'/'+output+'/'+mouse in f:\n","                break\n","            dFF = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","            time_ = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","            time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","            period = find_avg_period(time_)\n","\n","           # Find where not NaN part of dFF starts \n","            i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","            t0 = time_[i0]+win\n","            if time_m[-1] < time_[-1]:\n","              t1 = time_m[-1] - 2*win\n","            else:\n","              t1 = time_[-1] - 2*win\n","\n","            timestamps1 = np.array(f['Events/'+test+'/'+event[0]+'/'+mouse+'/'+trial+'/timestamps'])\n","            if len(timestamps1) != 0:\n","             # Remove events that fall to NaN part of dFF\n","              on_off_1 = timestamps1[np.all(timestamps1 > t0, axis=1)]\n","              on_off_1 = on_off_1[np.all(on_off_1 < t1, axis=1)]\n","             # Adjust timestamps to time vector\n","              inds1 = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off_1]\n","              on_off_1 = [ [time_[i],time_[j]] for i,j in inds1]\n","              on_off_1 = np.array(on_off_1)\n","             # Off event time\n","              off_on_1 = np.zeros(on_off_1.shape)\n","              off_on_1[0,0] = t0\n","              off_on_1[1:,0] = on_off_1[:-1,1]\n","              off_on_1[:,1] = on_off_1[:,0]\n","             # Onsets and offset\n","              on_1 = np.array(on_off_1[:,0])\n","              off_1 = np.array(on_off_1[:,1])\n","             # Adjust off time\n","              off_on_1 = adjust_intervals_durations(off_on_1,min_duration=2*win)\n","            else:\n","              on_1 = []\n","              off_1 = []\n","              off_on_1 = []\n","            \n","\n","            timestamps2 = np.array(f['Events/'+test+'/'+event[1]+'/'+mouse+'/'+trial+'/timestamps'])\n","            if len(timestamps2) != 0:\n","             # Remove events that fall to NaN part of dFF\n","              on_off_2 = timestamps2[np.all(timestamps2 > t0, axis=1)]\n","              on_off_2 = on_off_2[np.all(on_off_2 < t1, axis=1)]\n","             # Adjust timestamps to time vector\n","              inds2 = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off_2]\n","              on_off_2 = [ [time_[i],time_[j]] for i,j in inds2]\n","              on_off_2 = np.array(on_off_2)\n","             # Off event time\n","              off_on_2 = np.zeros(on_off_2.shape)\n","              off_on_2[0,0] = t0\n","              off_on_2[1:,0] = on_off_2[:-1,1]\n","              off_on_2[:,1] = on_off_2[:,0]\n","             # Onsets and offsets\n","              on_2 = np.array(on_off_2[:,0])\n","              off_2 = np.array(on_off_2[:,1])\n","             # Adjust off time\n","              off_on_2 = adjust_intervals_durations(off_on_2,min_duration=2*win)\n","            else:\n","              on_2 = []\n","              off_2 = []\n","              off_on_2 = []\n","           \n","           # Combine two off event times\n","            if len(off_on_1) == 0:\n","              off_on = off_on_2\n","            elif len(off_on_2) == 0:\n","              off_on = off_on_1\n","            else:\n","              off_on = np.concatenate((off_on_1,off_on_2),axis=0)\n","\n","           # Get random timestamps in off event time\n","            other = []\n","            for i,j in off_on:\n","              other.extend(np.arange(i+win,j-win+period,period))\n","\n","             # Choose subset of 50 events\n","            other = np.array(random_subset(other, 50))\n","\n","            path = 'MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event[0]+'-'+event[1]+'/'\n","            saveToHDF(f,path+event[0]+'-onset/'+mouse+'/'+trial,on_1)\n","            saveToHDF(f,path+event[0]+'-offset/'+mouse+'/'+trial,off_1)\n","            saveToHDF(f,path+event[1]+'-onset/'+mouse+'/'+trial,on_2)\n","            saveToHDF(f,path+event[1]+'-offset/'+mouse+'/'+trial,off_2)\n","            saveToHDF(f,path+'other/'+mouse+'/'+trial,other)\n","\n","        event = event[0]+'-'+event[1]\n","\n","      else:\n","\n","       # Choose events\n","        for mouse in f['Events/'+test+'/'+event]:\n","          for trial in f['Events/'+test+'/'+event+'/'+mouse]:\n","\n","            outputs = list(f['DFFs/'+test])\n","            for output in outputs:\n","              if 'DFFs/'+test+'/'+output+'/'+mouse in f:\n","                break\n","            dFF = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","            time_ = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","            time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","            period = find_avg_period(time_)\n","              \n","            timestamps = np.array(f['Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/timestamps'])\n","\n","            if timestamps.shape[1]==1:\n","\n","            # Find where not NaN part of dFF starts \n","              i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","              t0 = time_[i0]+win\n","              if time_m[-1] < time_[-1]:\n","                t1 = time_m[-1]-2*win\n","              else:\n","                t1 = time_[-1]-2*win\n","\n","            # Remove events that fall to NaN part of dFF\n","              on = timestamps[np.all(timestamps > t0, axis=1)]\n","              on = on[np.all(on < t1, axis=1)]\n","\n","            # Adjust timestamps to time vector\n","              inds = [ find_idx(i,time_) for i in on]\n","              on = [ time_[i] for i in inds]\n","              on = np.array(on)\n","\n","              other = []\n","              for i in on:\n","                other.extend(np.arange(i-win,i+win+period,period))\n","\n","            # Choose subset of 50 events\n","              other = np.array(random_subset(other, 50))\n","\n","              path = 'MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event+'/'\n","              saveToHDF(f,path+event+'/'+mouse+'/'+trial,on)\n","              saveToHDF(f,path+'other/'+mouse+'/'+trial,other)\n","\n","            else:\n","              if other_events == 'other':\n","\n","              # Find where not NaN part of dFF starts \n","                i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","                t0 = time_[i0]+win\n","                if time_m[-1]<time_[-1]:\n","                  t1 = time_m[-1]-2*win\n","                else:\n","                  t1 = time_[-1]-2*win\n","\n","              # Remove events that fall to NaN part of dFF\n","                on_off = timestamps[np.all(timestamps > t0, axis=1)]\n","                on_off = on_off[np.all(on_off < t1, axis=1)]\n","\n","              # Adjust timestamps to time vector\n","                inds = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off]\n","                on_off = [ [time_[i],time_[j]] for i,j in inds]\n","                on_off = np.array(on_off)\n","\n","                off_on = np.zeros(on_off.shape)\n","                off_on[0,0] = t0\n","                off_on[1:,0] = on_off[:-1,1]\n","                off_on[:,1] = on_off[:,0]\n","\n","                on = np.array(on_off[:,0])\n","                off = np.array(on_off[:,1])\n","\n","                off_on = adjust_intervals_durations(off_on,min_duration=2*win)\n","\n","                other = []\n","                for i,j in off_on:\n","                  other.extend(np.arange(i+win,j-win+period,period))\n","\n","              # Choose subset of 50 events\n","                other = np.array(random_subset(other, 50))\n","\n","                path = 'MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event+'/'\n","                saveToHDF(f,path+'onset/'+mouse+'/'+trial,on)\n","                saveToHDF(f,path+'offset/'+mouse+'/'+trial,off)\n","                saveToHDF(f,path+'other/'+mouse+'/'+trial,other)\n","\n","              elif other_events == 'inbetween':\n","\n","              # Find where not NaN part of dFF starts \n","                i0 = np.max(np.argwhere(np.isnan(dFF))) + 1\n","                t0 = time_[i0]+2*win\n","                if time_m[-1]<time_[-1]:\n","                  t1 = time_m[-1]-2*win\n","                else:\n","                  t1 = time_[-1]-2*win\n","\n","              # Remove events that fall to NaN part of dFF\n","                on_off = timestamps[np.all(timestamps > t0, axis=1)]\n","                on_off = on_off[np.all(on_off < t1, axis=1)]\n","\n","              # Adjust timestamps to time vector\n","                inds = [ [find_idx(i,time_),find_idx(j,time_)] for i,j in on_off]\n","                on_off = [ [time_[i],time_[j]] for i,j in inds]\n","                on_off = np.array(on_off)\n","\n","                off_on = np.zeros(on_off.shape)\n","                off_on[0,0] = t0\n","                off_on[1:,0] = on_off[:-1,1]\n","                off_on[:,1] = on_off[:,0]\n","\n","                onoffsets = adjust_intervals_durations(on_off,min_duration,min_interval)\n","                on = np.array(onoffsets[:,0])\n","                off = np.array(onoffsets[:,1])\n","\n","                on_off = adjust_intervals_durations(on_off,min_duration=2*win)\n","                off_on = adjust_intervals_durations(off_on,min_duration=2*win)\n","\n","                dur_on_off = []\n","                for i,j in on_off:\n","                  dur_on_off.extend(np.arange(i+win,j-win+period,period))\n","                dur_off_on = []\n","                for i,j in off_on:\n","                  dur_off_on.extend(np.arange(i+win,j-win+period,period))\n","\n","              # Choose subset of 50 events\n","                dur_on_off = np.array(random_subset(dur_on_off, 50))\n","                dur_off_on = np.array(random_subset(dur_off_on, 50))\n","\n","                path = 'MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event+'/'\n","                saveToHDF(f,path+'onset/'+mouse+'/'+trial,on)\n","                saveToHDF(f,path+'on-off/'+mouse+'/'+trial,dur_on_off)\n","                saveToHDF(f,path+'offset/'+mouse+'/'+trial,off)\n","                saveToHDF(f,path+'off-on/'+mouse+'/'+trial,dur_off_on)\n","\n","     # Calculate perievent correlation\n","      for output in f['DFFs/'+test]:\n","        for mouse in f['DFFs/'+test+'/'+output]:\n","\n","          for e_part in f['MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event]:\n","\n","            lags = []\n","            corrs = []\n","            maxlags = []\n","            maxcorrs = []\n","            Rs = []\n","            ps = []\n","\n","            for trial in f['DFFs/'+test+'/'+output+'/'+mouse]:\n","\n","              if self.goodRecordings != []:\n","                if [mouse, test, trial, output] in self.goodRecordings:\n","\n","                  signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                  time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                  measurement = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/values'])\n","                  time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","\n","                  T_s = find_avg_period(time_s)\n","                  T_m = find_avg_period(time_m)\n","                  if T_s != T_m:\n","                    return print('Interpolate signals.')\n","\n","                  timestamps = np.array(f['MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+mouse+'/'+trial])\n","\n","                  if len(timestamps) != 0:\n","                    for t in timestamps:\n","\n","                      idx = find_idx(t,time_s)\n","                      w = int(round(win/T_s))\n","\n","                      s = signal[idx-w:idx+w+1]\n","                      m = measurement[idx-w:idx+w+1]\n","\n","                      lag, corr = xcorr(s,m,True,True,maxlags=w)\n","                      idx_maxlag = np.argmax(np.abs(corr))\n","                      maxcorr = corr[idx_maxlag]\n","                      maxlag = lag[idx_maxlag]\n","\n","                      s = signal[idx+maxlag-w:idx+maxlag+w+1]\n","\n","                      R,p = pearsonr(s, m)\n","\n","                      lag = [i*T_s for i in lag]\n","                      maxlag = maxlag*T_s\n","\n","                      lags.append(lag)\n","                      corrs.append(corr)\n","                      maxlags.append(maxlag)\n","                      maxcorrs.append(maxcorr)\n","                      Rs.append(R)\n","                      ps.append(p)\n","\n","                  path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'+mouse\n","                  saveToHDF(f,path+'/lag',lags)\n","                  saveToHDF(f,path+'/corr',corrs)\n","                  #saveToHDF(f,path+'/max-lag',maxlags)\n","                  #saveToHDF(f,path+'/max-corr',maxcorrs)\n","                  saveToHDF(f,path+'/R',Rs)\n","                  saveToHDF(f,path+'/pvalue',ps)\n","\n","              else:\n","                \n","                signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                measurement = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/values'])\n","                time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","\n","                T_s = find_avg_period(time_s)\n","                T_m = find_avg_period(time_m)\n","                if T_s != T_m:\n","                  return print('Interpolate signals.')\n","\n","                timestamps = np.array(f['MeasurePerieventCorrelation/events/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+mouse+'/'+trial])\n","\n","                if len(timestamps) != 0:\n","                  for t in timestamps:\n","\n","                    idx = find_idx(t,time_s)\n","                    w = int(round(win/T_s))\n","\n","                    s = signal[idx-w:idx+w+1]\n","                    m = measurement[idx-w:idx+w+1]\n","\n","                    lag, corr = xcorr(s,m,True,True,maxlags=w)\n","                    idx_maxlag = np.argmax(np.abs(corr))\n","                    maxcorr = corr[idx_maxlag]\n","                    maxlag = lag[idx_maxlag]\n","\n","                    s = signal[idx+maxlag-w:idx+maxlag+w+1]\n","\n","                    R,p = pearsonr(s, m)\n","\n","                    lag = [i*T_s for i in lag]\n","                    maxlag = maxlag*time_s\n","                    \n","                    lags.append(lag)\n","                    corrs.append(corr)\n","                    maxlags.append(maxlag)\n","                    maxcorrs.append(maxcorr)\n","                    Rs.append(R)\n","                    ps.append(p)\n","\n","                path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'+mouse\n","                saveToHDF(f,path+'/lag',lags)\n","                saveToHDF(f,path+'/corr',corrs)\n","                #saveToHDF(f,path+'/max-lag',maxlags)\n","                #saveToHDF(f,path+'/max-corr',maxcorrs)\n","                saveToHDF(f,path+'/R',Rs)\n","                saveToHDF(f,path+'/pvalue',ps)\n","\n","\n","     # Count positive/negative/not correlations \n","      for e_part in f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event]:\n","        for output in f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part]:\n","\n","          mice = []\n","          list_not_corr = []\n","          list_pos_corr = []\n","          list_neg_corr = []\n","\n","          for mouse in f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output]:\n","            \n","            ps = np.array(f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'+mouse+'/pvalue'])\n","            Rs = np.array(f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'+mouse+'/R'])\n","\n","            if len(ps) != 0:\n","              n = len(ps)                               # total number events\n","              corr = Rs[(ps<0.001) & (np.abs(Rs)>0.6)]  # list of correlated events\n","              not_corr = (n - len(corr)) / n            # % of not correlated event\n","              pos_corr = sum(corr>0) / n                # % of positive correlated\n","              neg_corr = sum(corr<0) / n                # % of negative correlated\n","\n","              mice.append(mouse)\n","              list_not_corr.append(not_corr)\n","              list_pos_corr.append(pos_corr)\n","              list_neg_corr.append(neg_corr)\n","\n","          #print(output,e_part)  \n","          #print(np.array([mice,list_pos_corr,list_neg_corr,list_not_corr]).T)\n","\n","          path = 'MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output\n","          saveToHDF(f,path+'/mice',np.array(mice,dtype=h5py.string_dtype(encoding='utf-8')))\n","          saveToHDF(f,path+'/not-corr',list_not_corr)\n","          saveToHDF(f,path+'/pos-corr',list_pos_corr)\n","          saveToHDF(f,path+'/neg-corr',list_neg_corr)\n","\n","\n","\n","\n","  def getMeasureCrossCorrelation(self,measure,event,e_part='onset',win=[-3,3]):\n","\n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","    \n","      for output in f['DFFs/'+test]:\n","          for mouse in f['DFFs/'+test+'/'+output]:\n","\n","            lags = []\n","            corrs = []\n","            maxlags = []\n","            maxcorrs = []\n","            Rs = []\n","            ps = []\n","\n","            for trial in f['DFFs/'+test+'/'+output+'/'+mouse]:\n","\n","              if self.goodRecordings != []:\n","                if [mouse, test, trial, output] in self.goodRecordings:\n","\n","                  signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                  time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                  measurement = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/values'])\n","                  time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","\n","                  T_s = find_avg_period(time_s)\n","                  T_m = find_avg_period(time_m)\n","                  if T_s != T_m:\n","                    return print('Interpolate signals.')\n","\n","                  timestamps = np.array(f['Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/timestamps'])\n","\n","                  if len(timestamps) != 0:\n","\n","                    if e_part == 'onset':\n","                      timestamps = timestamps[:,0]\n","                    elif e_part == 'offset':\n","                      timestamps = timestamps[:,1]\n","\n","                  # Find where not NaN part of dFF starts \n","                    i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","                    t0 = time_s[i0] + (win[1]-win[0])\n","                    if time_m[-1]<time_s[-1]:\n","                      t1 = time_m[-1] - (win[1]-win[0])\n","                    else:\n","                      t1 = time_s[-1] - (win[1]-win[0])\n","                  # Remove events that fall to NaN part of dFF\n","                    timestamps = timestamps[timestamps > t0]\n","                    timestamps = timestamps[timestamps < t1]\n","\n","\n","                    for t in timestamps:\n","\n","                      idx = find_idx(t,time_s)\n","                      w0 = int(round(win[0]/T_s))\n","                      w1 = int(round(win[1]/T_s))\n","                      w = int(round((win[1]-win[0])/T_s/2))\n","\n","                      s = signal[idx+w0:idx+w1+1]\n","                      m = measurement[idx+w0:idx+w1+1]\n","\n","                      lag, corr = xcorr(s,m,True,True,maxlags=w)\n","                      idx_maxlag = np.argmax(np.abs(corr))\n","                      maxcorr = corr[idx_maxlag]\n","                      maxlag = lag[idx_maxlag]\n","\n","                      s = signal[idx+maxlag+w0:idx+maxlag+w1+1]\n","                      R,p = pearsonr(s, m)\n","\n","                      lag = [i*T_s for i in lag]\n","                      maxlag = maxlag*T_s\n","\n","                      lags.append(lag)\n","                      corrs.append(corr)\n","                      maxlags.append(maxlag)\n","                      maxcorrs.append(maxcorr)\n","                      Rs.append(R)\n","                      ps.append(p)\n","\n","                    path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'+mouse\n","                    saveToHDF(f,path+'/lag',lags)\n","                    saveToHDF(f,path+'/corr',corrs)\n","                    #saveToHDF(f,path+'/max-lag',maxlags)\n","                    #saveToHDF(f,path+'/max-corr',maxcorrs)\n","                    saveToHDF(f,path+'/R',Rs)\n","                    saveToHDF(f,path+'/pvalue',ps)\n","\n","              else:\n","                \n","                signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","                time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","                measurement = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/values'])\n","                time_m = np.array(f['Measurements/'+test+'/'+measure+'/'+mouse+'/'+trial+'/time'])\n","\n","                T_s = find_avg_period(time_s)\n","                T_m = find_avg_period(time_m)\n","                if T_s != T_m:\n","                  return print('Interpolate signals.')\n","\n","                timestamps = np.array(f['Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/timestamps'])\n","\n","                if len(timestamps) != 0:\n","\n","                  if e_part == 'onset':\n","                    timestamps = timestamps[:,0]\n","                  elif e_part == 'offset':\n","                    timestamps = timestamps[:,1]\n","\n","                # Find where not NaN part of dFF starts \n","                  i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","                  t0 = time_s[i0] + (win[1]-win[0])\n","                  if time_m[-1]<time_s[-1]:\n","                    t1 = time_m[-1] - (win[1]-win[0])\n","                  else:\n","                    t1 = time_s[-1] - (win[1])\n","                # Remove events that fall to NaN part of dFF\n","                  timestamps = timestamps[timestamps > t0]\n","                  timestamps = timestamps[timestamps < t1]\n","\n","\n","                  for t in timestamps:\n","\n","                    idx = find_idx(t,time_s)\n","                    w0 = int(round(win[0]/T_s))\n","                    w1 = int(round(win[1]/T_s))\n","                    w = int(round((win[1]-win[0])/T_s/2))\n","\n","                    s = signal[idx+w0:idx+w1+1]\n","                    m = measurement[idx+w0:idx+w1+1]\n","\n","                    lag, corr = xcorr(s,m,True,True,maxlags=w)\n","                    idx_maxlag = np.argmax(np.abs(corr))\n","                    maxcorr = corr[idx_maxlag]\n","                    maxlag = lag[idx_maxlag]\n","\n","                    s = signal[idx+maxlag+w0:idx+maxlag+w1+1]\n","                    R,p = pearsonr(s, m)\n","\n","                    lag = [i*T_s for i in lag]\n","                    maxlag = maxlag*T_s\n","                    \n","                    lags.append(lag)\n","                    corrs.append(corr)\n","                    maxlags.append(maxlag)\n","                    maxcorrs.append(maxcorr)\n","                    Rs.append(R)\n","                    ps.append(p)\n","\n","                  path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'+mouse\n","                  saveToHDF(f,path+'/lag',lags)\n","                  saveToHDF(f,path+'/corr',corrs)\n","                  #saveToHDF(f,path+'/max-lag',maxlags)\n","                  #saveToHDF(f,path+'/max-corr',maxcorrs)\n","                  saveToHDF(f,path+'/R',Rs)\n","                  saveToHDF(f,path+'/pvalue',ps)\n","\n","\n","\n","\n","  def getOutputCrossCorrelation(self,output,output1,event,e_part='onset',win=[-3,3]):\n","\n","    test = self.test\n","\n","    with h5py.File(self.filename, 'a') as f:\n","    \n","      for mouse in f['DFFs/'+test+'/'+output]:\n","\n","        lags = []\n","        corrs = []\n","        maxlags = []\n","        maxcorrs = []\n","        Rs = []\n","        ps = []\n","\n","        for trial in f['DFFs/'+test+'/'+output+'/'+mouse]:\n","\n","          if self.goodRecordings != []:\n","            if ([mouse,test,trial,output] in self.goodRecordings) and ([mouse,test,trial,output1] in self.goodRecordings):\n","\n","              print(mouse,trial,end=' ')\n","\n","              signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","              signal1 = np.array(f['DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF'])\n","              time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","\n","              T_s = find_avg_period(time_s)\n","\n","              timestamps = np.array(f['Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/timestamps'])\n","\n","              if len(timestamps) != 0:\n","\n","                if e_part == 'onset':\n","                  timestamps = timestamps[:,0]\n","                elif e_part == 'offset':\n","                  timestamps = timestamps[:,1]\n","\n","               # Find where not NaN part of dFF starts \n","                i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","                t0 = time_s[i0] + (win[1]-win[0])\n","                t1 = time_s[-1] - (win[1]-win[0])\n","               # Remove events that fall to NaN part of dFF\n","                timestamps = timestamps[timestamps > t0]\n","                timestamps = timestamps[timestamps < t1]\n","\n","\n","                for t in timestamps:\n","\n","                  idx = find_idx(t,time_s)\n","                  w0 = int(round(win[0]/T_s))\n","                  w1 = int(round(win[1]/T_s))\n","                  w = int(round((win[1]-win[0])/T_s/2))\n","\n","                  s = signal[idx+w0:idx+w1+1]\n","                  s1 = signal1[idx+w0:idx+w1+1]\n","\n","                  lag, corr = xcorr(s,s1,True,True,maxlags=w)\n","                  idx_maxlag = np.argmax(np.abs(corr))\n","                  maxcorr = corr[idx_maxlag]\n","                  maxlag = lag[idx_maxlag]\n","\n","                  s = signal[idx+maxlag+w0:idx+maxlag+w1+1]\n","                  R,p = pearsonr(s,s1)\n","\n","                  lag = [i*T_s for i in lag]\n","                  maxlag = maxlag*T_s\n","\n","                  lags.append(lag)\n","                  corrs.append(corr)\n","                  maxlags.append(maxlag)\n","                  maxcorrs.append(maxcorr)\n","                  Rs.append(R)\n","                  ps.append(p)\n","\n","                path = 'OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'+mouse\n","                saveToHDF(f,path+'/lag',lags)\n","                saveToHDF(f,path+'/corr',corrs)\n","                #saveToHDF(f,path+'/max-lag',maxlags)\n","                #saveToHDF(f,path+'/max-corr',maxcorrs)\n","                saveToHDF(f,path+'/R',Rs)\n","                saveToHDF(f,path+'/pvalue',ps)\n","\n","          else:\n","                \n","            signal = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/dFF'])\n","            signal1 = np.array(f['DFFs/'+test+'/'+output1+'/'+mouse+'/'+trial+'/dFF'])\n","            time_s = np.array(f['DFFs/'+test+'/'+output+'/'+mouse+'/'+trial+'/time'])\n","\n","            timestamps = np.array(f['Events/'+test+'/'+event+'/'+mouse+'/'+trial+'/timestamps'])\n","\n","            if len(timestamps) != 0:\n","\n","              if e_part == 'onset':\n","                timestamps = timestamps[:,0]\n","              elif e_part == 'offset':\n","                timestamps = timestamps[:,1]\n","\n","             # Find where not NaN part of dFF starts \n","              i0 = np.max(np.argwhere(np.isnan(signal))) + 1\n","              t0 = time_s[i0] + (win[1]-win[0])\n","              t1 = time_s[-1] - (win[1])\n","             # Remove events that fall to NaN part of dFF\n","              timestamps = timestamps[timestamps > t0]\n","              timestamps = timestamps[timestamps < t1]\n","\n","              for t in timestamps:\n","\n","                idx = find_idx(t,time_s)\n","                w0 = int(round(win[0]/T_s))\n","                w1 = int(round(win[1]/T_s))\n","                w = int(round((win[1]-win[0])/T_s/2))\n","\n","                s = signal[idx+w0:idx+w1+1]\n","                s1 = signal1[idx+w0:idx+w1+1]\n","\n","                lag, corr = xcorr(s,s1,True,True,maxlags=w)\n","                idx_maxlag = np.argmax(np.abs(corr))\n","                maxcorr = corr[idx_maxlag]\n","                maxlag = lag[idx_maxlag]\n","\n","                s = signal[idx+maxlag+w0:idx+maxlag+w1+1]\n","                R,p = pearsonr(s,s1)\n","\n","                lag = [i*T_s for i in lag]\n","                maxlag = maxlag*T_s\n","                    \n","                lags.append(lag)\n","                corrs.append(corr)\n","                maxlags.append(maxlag)\n","                maxcorrs.append(maxcorr)\n","                Rs.append(R)\n","                ps.append(p)\n","\n","              path = 'OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'+mouse\n","              saveToHDF(f,path+'/lag',lags)\n","              saveToHDF(f,path+'/corr',corrs)\n","              #saveToHDF(f,path+'/max-lag',maxlags)\n","              #saveToHDF(f,path+'/max-corr',maxcorrs)\n","              saveToHDF(f,path+'/R',Rs)\n","              saveToHDF(f,path+'/pvalue',ps)\n","\n","\n","\n","\n","  def plotOutputCorrelationCounts(self,output,output1,event,\n","                                  event_labels=None,error_type='SEM',**kwargs):\n","\n","    test = self.test\n","\n","    mean = []\n","    error = []\n","    labels = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for e_part in f['OutputPerieventCorrelation/counts/'+test+'/'+event]:\n","\n","        path = 'OutputPerieventCorrelation/counts/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1\n","\n","        not_corr = list(f[path+'/not-corr'])\n","        pos_corr = list(f[path+'/pos-corr'])\n","        neg_corr = list(f[path+'/neg-corr'])\n","\n","        mean_pos_corr,error_pos_corr = calculate_mean_error(pos_corr,error_type)\n","        mean_neg_corr,error_neg_corr = calculate_mean_error(neg_corr,error_type)\n","        mean_not_corr,error_not_corr = calculate_mean_error(not_corr,error_type)\n","\n","        mean.append([mean_pos_corr,mean_neg_corr,mean_not_corr])\n","        error.append([error_pos_corr,error_neg_corr,error_neg_corr])\n","          \n","        if event_labels is None:\n","          labels.append(e_part)\n","\n","      mean = np.array(mean).T\n","      error = np.array(error).T\n","\n","    if event_labels is None:\n","      event_labels = labels\n","\n","    plot_perievent_correlation_counts(mean,error,event_labels,**kwargs)\n","\n","\n","\n","\n","\n","  def plotMeasureCorrelationCounts(self,measure,output,event,\n","                                   event_labels=None,error_type='SEM',**kwargs):\n","\n","    test = self.test\n","\n","    mean = []\n","    error = []\n","    labels = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      if output == 'all':\n","\n","        for e_part in f['MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event]:\n","\n","          list_pos_corr = []\n","          list_neg_corr = []\n","          list_not_corr = []\n","\n","          for output in f['MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event+'/'+e_part]:\n","\n","            path = 'MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output\n","\n","            not_corr = list(f[path+'/not-corr'])\n","            pos_corr = list(f[path+'/pos-corr'])\n","            neg_corr = list(f[path+'/neg-corr'])\n","\n","            list_not_corr.extend(not_corr)\n","            list_pos_corr.extend(pos_corr)\n","            list_neg_corr.extend(neg_corr)\n","\n","          mean_pos_corr,error_pos_corr = calculate_mean_error(list_pos_corr,error_type)\n","          mean_neg_corr,error_neg_corr = calculate_mean_error(list_neg_corr,error_type)\n","          mean_not_corr,error_not_corr = calculate_mean_error(list_not_corr,error_type)\n","\n","          mean.append([mean_pos_corr,mean_neg_corr,mean_not_corr])\n","          error.append([error_pos_corr,error_neg_corr,error_neg_corr])\n","          \n","          if event_labels is None:\n","            labels.append(e_part)\n","\n","        mean = np.array(mean).T\n","        error = np.array(error).T\n","\n","      else:\n","\n","        for e_part in f['MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event]:\n","\n","          path = 'MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output\n","\n","          not_corr = list(f[path+'/not-corr'])\n","          pos_corr = list(f[path+'/pos-corr'])\n","          neg_corr = list(f[path+'/neg-corr'])\n","\n","          mean_pos_corr,error_pos_corr = calculate_mean_error(pos_corr,error_type)\n","          mean_neg_corr,error_neg_corr = calculate_mean_error(neg_corr,error_type)\n","          mean_not_corr,error_not_corr = calculate_mean_error(not_corr,error_type)\n","\n","          mean.append([mean_pos_corr,mean_neg_corr,mean_not_corr])\n","          error.append([error_pos_corr,error_neg_corr,error_neg_corr])\n","          \n","          if event_labels is None:\n","            labels.append(e_part)\n","\n","        mean = np.array(mean).T\n","        error = np.array(error).T\n","\n","      if event_labels is None:\n","        event_labels = labels\n","\n","      plot_perievent_correlation_counts(mean,error,event_labels,**kwargs)\n","\n","\n","\n","\n","  def plotMeasureCrossCorrelation(self,measure,output,event,e_part='onset',**kwargs):\n","\n","    from scipy.stats import mode\n","\n","    test = self.test\n","\n","    corrs = []\n","    lags = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      if output=='all':\n","\n","        for output in f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part]:\n","\n","          path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'\n","\n","          for mouse in f[path]:\n","\n","            Rs = np.array(f[path+mouse+'/R'])\n","            ps = np.array(f[path+mouse+'/pvalue'])\n","\n","            corr = np.array(f[path+mouse+'/corr'])\n","            lag = np.array(f[path+mouse+'/lag'])\n","\n","            if len(corrs) != 0: \n","              corr = corr[(ps<0.001) & (Rs>0.6)]\n","              lag = lag[(ps<0.001) & (Rs>0.6)]\n","\n","              corrs.append(np.median(corr,axis=0))\n","              lags.append(np.median(lag,axis=0))\n","\n","      else:\n","\n","        path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'\n","\n","        for mouse in f[path]:\n","\n","          Rs = np.array(f[path+mouse+'/R'])\n","          ps = np.array(f[path+mouse+'/pvalue'])\n","\n","          corr = np.array(f[path+mouse+'/corr'])\n","          lag = np.array(f[path+mouse+'/lag'])\n","\n","          if len(corr) != 0:\n","            corr = corr[(ps<0.001) & (Rs>0.6)]\n","            lag = lag[(ps<0.001) & (Rs>0.6)]\n","\n","            median_corr = np.mean(corr, axis=0)\n","            median_lag = np.mean(lag, axis=0)\n","\n","            corrs.append(median_corr)\n","            lags.append(median_lag)\n","\n","    nrow = len(corrs)\n","    ncol = len(corrs[0])\n","    corrs = np.array(corrs).reshape((nrow,ncol))\n","    lags = np.array(lags).reshape((nrow,ncol))\n","\n","    plot_crosscorrelation(lags[0],corrs,**kwargs)\n","\n","    #return corrs\n","\n","\n","\n","\n","  def plotOutputCrossCorrelation(self,output,output1,event,e_part='onset',**kwargs):\n","\n","    from scipy.stats import mode\n","\n","    test = self.test\n","\n","    corrs = []\n","    lags = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      path = 'OutputPerieventCorrelation/correlation/'+test+'/'+event+'/'+e_part+'/'+output+'_'+output1+'/'\n","\n","      for mouse in f[path]:\n","\n","        Rs = np.array(f[path+mouse+'/R'])\n","        ps = np.array(f[path+mouse+'/pvalue'])\n","\n","        corr = np.array(f[path+mouse+'/corr'])\n","        lag = np.array(f[path+mouse+'/lag'])\n","\n","        if len(corr) != 0:\n","          corr = corr[(ps<0.001) & (Rs>0.6)]\n","          lag = lag[(ps<0.001) & (Rs>0.6)]\n","\n","          median_corr = np.median(corr, axis=0)\n","          median_lag =np.median(lag, axis=0)\n","\n","          corrs.append(median_corr)\n","          lags.append(median_lag)\n","\n","    nrow = len(corrs)\n","    ncol = len(corrs[0])\n","    corrs = np.array(corrs).reshape((nrow,ncol))\n","    lags = np.array(lags).reshape((nrow,ncol))\n","\n","    plot_crosscorrelation(lags[0],corrs,**kwargs)\n","\n","    #return corrs\n","\n","\n","\n","\n","  def getDataFrameCrossCorr(self,measure,event,e_part,\n","                          save=False,csvname='crosscorr.csv'):\n","\n","    test = self.test\n","\n","    mice_list = []\n","    output_list = []\n","    maxlag_list = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for output in f['MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part]:\n","\n","        path = 'MeasurePerieventCorrelation/correlation/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output+'/'\n","\n","        for mouse in f[path]:\n","\n","          Rs = np.array(f[path+mouse+'/R'])\n","          ps = np.array(f[path+mouse+'/pvalue'])\n","\n","          corr = np.array(f[path+mouse+'/corr'])\n","          lag = np.array(f[path+mouse+'/lag'])[0]\n"," \n","          corr = corr[(ps<0.001) & (Rs>0.6)]\n","          median_corr = np.median(corr, axis=0)\n","\n","          sm_corr = smooth_signal(median_corr,5)\n","          maxlag = get_midline(lag,sm_corr)\n","\n","          mice_list.append(mouse)\n","          maxlag_list.append(maxlag)\n","          output_list.append(output)\n","          \n","\n","    df = pd.DataFrame({'mouse': mice_list,\n","                      'output': output_list,\n","                      'maxlag': maxlag_list})\n","      \n","    if save:\n","      df.to_csv(csvname,index=False)\n","\n","    return df\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uwClG3MSUEH"},"source":["# Experiment Class"]},{"cell_type":"code","metadata":{"id":"EUULos6aJS7F"},"source":["class FiberPhotometryExperiment:\n","  def __init__(self,filename):\n","    self.filename = filename\n","    with h5py.File(filename,'r') as f:\n","      try:\n","        self.mice = list(f.attrs['mice'])\n","        self.outputs = list(f.attrs['outputs'])\n","        self.tests = list(f.attrs['tests'])\n","        self.goodRecordings = list(f.attrs['good recordings'])\n","        print('Tests information is successfully loaded.')\n","      except:\n","        print('Set names of mice, outputs/pathways recorded and good recordings\\nas attributes of HDF file, and create the object again')\n","\n","  \n","\n","  def plotRoverTests(self,output,output1=None,measure=None,tests='all',**kwargs):\n","\n","    if (output1 is not None) and (measure is not None):\n","      print('Choose to plot correlation of 2 different outups/paths or 1 output/path and 1 measure.')\n","      return\n","\n","    if tests == 'all':\n","      tests = self.tests\n","\n","    list_Rs = []\n","    list_tests = []\n","\n","    with h5py.File(self.filename, 'r') as f:\n","      \n","      if output == 'all':\n","\n","        if output1 is not None:\n","\n","          for test in tests:\n","            for output in self.outputs:\n","              Rs = list(f['OutputCorrelation/'+test+'/'+output+'_'+output1+'/R'])\n","              list_Rs.extend(Rs)\n","              list_tests.extend([test]*len(Rs))\n","      \n","        if measure is not None:\n","\n","          for test in tests:\n","            for output in self.outputs:\n","              Rs = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/R'])\n","              list_Rs.extend(Rs)\n","              list_tests.extend([test]*len(Rs))\n","      \n","      else:\n","\n","        if output1 is not None:\n","          for test in tests:\n","            Rs = list(f['OutputCorrelation/'+test+'/'+output+'_'+output1+'/R'])\n","            list_Rs.extend(Rs)\n","            list_tests.extend([test]*len(Rs))\n","\n","        elif measure is not None:\n","          for test in tests:\n","            Rs = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/R'])\n","            list_Rs.extend(Rs)\n","            list_tests.extend([test]*len(Rs))\n","\n","    plot_violinplot(list_tests,list_Rs,**kwargs)\n","\n","    return\n","\n","\n","\n","\n","  def getDataFrameAUC(self,tests,events,onoffset,periods=['baseline','event'],\n","                      save=False,csvname='auc.csv'):\n","\n","    test = self.test\n","\n","    mice_list = []\n","    output_list = []\n","    period_list = []\n","    auc_list = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for output in f['Means/'+test]:\n","\n","        path = 'Means/'+test+'/'+output+'/'+event+'/'+onoffset+'/'\n","        mice = list(f[path+'mice'])\n","        auc = np.array(f[path+'auc'])\n","\n","        for i,period in enumerate(periods):\n","\n","          n = len(mice)\n","          mice_list.extend(mice)\n","          output_list.extend([output]*n)\n","          period_list.extend([period]*n)\n","          auc_list.extend(list(auc[:,i]))\n","\n","\n","      df = pd.DataFrame({'mouse': mice_list,\n","                        'output': output_list,\n","                        'period': period_list,\n","                           'auc': auc_list})\n","      \n","      if save:\n","        df.to_csv(csvname,index=False)\n","\n","    return df\n","\n","\n","\n","  \n","  def getDataFrameMeasureCorrCounts(self,measure,tests=None,outputs=None,\n","                                    save=True,csvname='corrcounts.csv'):\n","    \n","    mice_list = []\n","    test_list = []\n","    output_list = []\n","    event_list = []\n","    pos_corr_list = []\n","    neg_corr_list = []\n","    not_corr_list = []\n","\n","\n","    if tests == None:\n","      tests = self.tests\n","    if outputs == None:\n","      outputs = self.outputs\n","    \n","    with h5py.File(self.filename, 'r') as f:\n","\n","      for test in tests:\n","        for output in outputs:\n","\n","          for event in f['MeasurePerieventCorrelation/counts/'+test+'/'+measure]:\n","            for e_part in f['MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event]:\n","\n","              path = 'MeasurePerieventCorrelation/counts/'+test+'/'+measure+'/'+event+'/'+e_part+'/'+output\n","\n","              mice = np.array(f[path+'/mice'])\n","              pos_corr = np.array(f[path+'/pos-corr'])\n","              neg_corr = np.array(f[path+'/neg-corr'])\n","              not_corr = np.array(f[path+'/not-corr'])\n","\n","              mice_list.extend(mice)\n","              test_list.extend([test]*len(mice))\n","              output_list.extend([output]*len(mice))\n","              event_list.extend([event+'_'+e_part]*len(mice))\n","              pos_corr_list.extend(pos_corr)\n","              neg_corr_list.extend(neg_corr)\n","              not_corr_list.extend(not_corr)\n","    \n","\n","    df = pd.DataFrame({'mouse': mice_list,\n","                        'test': test_list,\n","                      'output': output_list,\n","                       'event': event_list,\n","                    'pos-corr': pos_corr_list,\n","                    'neg-corr': neg_corr_list,\n","                    'not-corr': not_corr_list})\n","    \n","    return df\n","\n","\n","\n","\n","\n","  def getDataFrameOutputCorrCounts(self,tests=None,\n","                                  save=True,csvname='corrcounts.csv'):\n","    \n","    mice_list = []\n","    test_list = []\n","    output_list = []\n","    event_list = []\n","    pos_corr_list = []\n","    neg_corr_list = []\n","    not_corr_list = []\n","\n","\n","    if tests == None:\n","      tests = self.tests\n","    \n","    with h5py.File(self.filename, 'r') as f:\n","\n","      for test in tests:\n","\n","        for event in f['OutputPerieventCorrelation/counts/'+test]:\n","          for e_part in f['OutputPerieventCorrelation/counts/'+test+'/'+event]:\n","            for output in f['OutputPerieventCorrelation/counts/'+test+'/'+event+'/'+e_part]:\n","\n","              path = 'OutputPerieventCorrelation/counts/'+test+'/'+event+'/'+e_part+'/'+output\n","\n","              mice = np.array(f[path+'/mice'])\n","              pos_corr = np.array(f[path+'/pos-corr'])\n","              neg_corr = np.array(f[path+'/neg-corr'])\n","              not_corr = np.array(f[path+'/not-corr'])\n","\n","              mice_list.extend(mice)\n","              test_list.extend([test]*len(mice))\n","              output_list.extend([output]*len(mice))\n","              event_list.extend([event+'_'+e_part]*len(mice))\n","              pos_corr_list.extend(pos_corr)\n","              neg_corr_list.extend(neg_corr)\n","              not_corr_list.extend(not_corr)\n","    \n","\n","    df = pd.DataFrame({'mouse': mice_list,\n","                        'test': test_list,\n","                     'outputs': output_list,\n","                       'event': event_list,\n","                    'pos-corr': pos_corr_list,\n","                    'neg-corr': neg_corr_list,\n","                    'not-corr': not_corr_list})\n","    \n","    return df\n","\n","\n","\n","  # def plotRoverTests(self,output,output1=None,measure=None,tests='all',**kwargs):\n","\n","  #   if (output1 is not None) and (measure is not None):\n","  #     print('Choose to plot correlation of 2 different outups/paths or 1 output/path and 1 measure.')\n","  #     return\n","\n","  #   if tests == 'all':\n","  #     tests = self.tests\n","\n","  #   list_Rs = []\n","  #   list_tests = []\n","\n","  #   with h5py.File(self.filename, 'r') as f:\n","      \n","  #     if output == 'all':\n","\n","  #       if output1 is not None:\n","\n","  #         for test in tests:\n","  #           for output in self.outputs:\n","  #             Rs = list(f['OutputCorrelation/'+test+'/'+output+'/'+output1+'/R'])\n","  #             list_Rs.extend(Rs)\n","  #             list_tests.extend([test]*len(Rs))\n","      \n","  #       if measure is not None:\n","\n","  #         for test in tests:\n","  #           for output in self.outputs:\n","  #             Rs = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/R'])\n","  #             list_Rs.extend(Rs)\n","  #             list_tests.extend([test]*len(Rs))\n","      \n","  #     else:\n","\n","  #       if output1 is not None:\n","  #         for test in tests:\n","  #           Rs = list(f['OutputCorrelation/'+test+'/'+output+'/'+output1+'/R'])\n","  #           list_Rs.extend(Rs)\n","  #           list_tests.extend([test]*len(Rs))\n","\n","  #       elif measure is not None:\n","  #         for test in tests:\n","  #           Rs = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/R'])\n","  #           list_Rs.extend(Rs)\n","  #           list_tests.extend([test]*len(Rs))\n","\n","  #   plot_violinplot(list_tests,list_Rs,**kwargs)\n","\n","  #   return\n","\n","\n","\n","  def getDataFrameRmeasure(self,measure,tests='all',\n","                          save=False,csvname='R.csv'):\n","\n","    if tests == 'all':\n","      tests = self.tests\n","\n","    mice_list = []\n","    test_list = []\n","    output_list = []\n","    R_list = []\n","    p_list = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for test in tests:\n","        for output in f['MeasureCorrelation/'+test+'/'+measure]:\n","          mice = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/mice'])\n","          Rs = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/R'])\n","          ps = list(f['MeasureCorrelation/'+test+'/'+measure+'/'+output+'/p-value'])\n","\n","          mice_list.extend(mice)\n","          R_list.extend(Rs)\n","          p_list.extend(ps)\n","          output_list.extend([output]*len(Rs))\n","          test_list.extend([test]*len(Rs))\n","\n","      df = pd.DataFrame({'mouse': mice_list,\n","                          'test': test_list,\n","                        'output': output_list,\n","                             'R': R_list,\n","                        'pvalue': p_list})\n","      \n","      if save:\n","        df.to_csv(csvname,index=False)\n","\n","    return df\n","\n","\n","\n","    \n","\n","  def getDataFrameRoutputs(self,tests='all',\n","                          save=False,csvname='R.csv'):\n","\n","    if tests == 'all':\n","      tests = self.tests\n","\n","    mice_list = []\n","    test_list = []\n","    output_list = []\n","    R_list = []\n","    p_list = []\n","\n","    with h5py.File(self.filename,'r') as f:\n","\n","      for test in tests:\n","        for output in f['OutputCorrelation/'+test]:\n","          mice = list(f['OutputCorrelation/'+test+'/'+output+'/mice'])\n","          Rs = list(f['OutputCorrelation/'+test+'/'+output+'/R'])\n","          ps = list(f['OutputCorrelation/'+test+'/'+output+'/p-value'])\n","\n","          mice_list.extend(mice)\n","          R_list.extend(Rs)\n","          p_list.extend(ps)\n","          output_list.extend([output]*len(Rs))\n","          test_list.extend([test]*len(Rs))\n","\n","      df = pd.DataFrame({'mouse': mice_list,\n","                          'test': test_list,\n","                        'output': output_list,\n","                             'R': R_list,\n","                        'pvalue': p_list})\n","      \n","      if save:\n","        df.to_csv(csvname,index=False)\n","\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNH7S7V9ed9w"},"source":["def isbinary(vector):\n","  return np.array_equal(vector, vector.astype(bool))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N3NI241Dg-t_"},"source":["def arebinary(dictionary):\n","\n","  for key in dictionary:\n","    if not isbinary(dictionary[key]['values']):\n","      return False\n","      break\n","  else:\n","    return True    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7zw6CMjqHdS"},"source":["def interpolate_signal(signal,t_old,t_new):\n","\n","  from scipy.interpolate import interp1d\n","\n","  func = interp1d(t_old,signal)\n","  s_new = func(t_new)\n","\n","  return s_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NKSWPmtcI-xk"},"source":["def saveToHDF(f,path,data):\n","\n","  try:\n","    f.create_dataset(path,data=data)\n","  except ValueError:\n","    try:\n","      f[path][()] = data\n","    except TypeError:\n","      del f[path]\n","      f.create_dataset(path,data=data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTtMmRhRgKYX"},"source":["def calculate_auc(means, period=0.10, window=[-5.0,5.0], time_frames=[[-3,0],[0,3]]):\n","\n","  from sklearn import metrics\n","\n","  t = create_centered_time_vector(period,window)\n","\n","  stats = np.zeros([len(means),len(time_frames)])\n","\n","  for i,frame in enumerate(time_frames):\n","    idx = [i for i in range(len(t)) if t[i]>frame[0] and t[i]<frame[1]]\n","    #stats1 = np.mean(means[:,idx],axis=1)\n","    for m in range(len(means)):\n","      auc = metrics.auc(t[idx],means[m,idx])\n","      stats[m,i] = auc / (frame[1] - frame[0])\n","\n","  return stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AR6f8HbI9ICm"},"source":["# Check if experiment is in the list of god recordings\n","def isGoodRecording(goodRecordings,mouse,test,trial=None,output=None):\n","\n","  goodMouse = [i for i in range(len(goodRecordings)) if goodRecordings[idx,0]==mouse]\n","\n","  goodTest = [i for i in range(len(goodRecordings)) if goodRecordings[idx,1]==test]\n","\n","  if trial is not None:\n","    goodTrial = [i for i in range(len(goodRecordings)) if goodRecordings[idx,2]==trial]\n","  else: \n","    goodTrial = range(len(goodRecordings))\n","\n","  if output is not None:\n","    goodOutput = [i for i in range(len(goodRecordings)) if goodRecordings[idx,3]==trial]\n","  else:\n","    goodOutput = range(len(goodRecordings))\n","\n","  intersection = list(set(goodMouse)&set(goodTest)&set(goodTrial)&set(goodOutput))\n","\n","  return intersection != []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DtUmdBcwjtH_"},"source":["# Data processing helper functions"]},{"cell_type":"markdown","metadata":{"id":"lTv0DQjOLQis"},"source":["### Preprocess"]},{"cell_type":"code","metadata":{"id":"RFTik3eor_C8"},"source":["def smooth_signal(x,window_len=10,window='flat'):\n","\n","    \"\"\"smooth the data using a window with requested size.\n","    \n","    This method is based on the convolution of a scaled window with the signal.\n","    The signal is prepared by introducing reflected copies of the signal \n","    (with the window size) in both ends so that transient parts are minimized\n","    in the begining and end part of the output signal.\n","    The code taken from: https://scipy-cookbook.readthedocs.io/items/SignalSmooth.html\n","    \n","    input:\n","        x: the input signal \n","        window_len: the dimension of the smoothing window; should be an odd integer\n","        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n","                'flat' window will produce a moving average smoothing.\n","\n","    output:\n","        the smoothed signal        \n","    \"\"\"\n","\n","    if x.ndim != 1:\n","        raise(ValueError, \"smooth only accepts 1 dimension arrays.\")\n","\n","    if x.size < window_len:\n","        raise(ValueError, \"Input vector needs to be bigger than window size.\")\n","\n","    if window_len<3:\n","        return x\n","\n","    if window_len % 2 == 1:\n","      window_len -= 1\n","\n","    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n","        raise(ValueError, \"Window is one of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n","\n","    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n","\n","    if window == 'flat': # Moving average\n","        w=np.ones(window_len,'d')\n","    else:\n","        w=eval('np.'+window+'(window_len)')\n","\n","    y=np.convolve(w/w.sum(),s,mode='valid')\n","\n","    return y[(int(window_len/2)-1):-int(window_len/2)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6nAnxJOqM7v"},"source":["from scipy.signal import butter, filtfilt, freqz\n","\n","def butter_lowpass(cutoff, fs, order=10):\n","    nyq = 0.5 * fs\n","    normal_cutoff = cutoff / nyq\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    return b, a\n","\n","\n","def butter_lowpass_filter(data, cutoff, fs, order=10):\n","    b, a = butter_lowpass(cutoff, fs, order=order)\n","    y = filtfilt(b, a, data)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrHmsfWeQnMk"},"source":["def flatten_signal(signal,lambda_=1e4,order=0.5,itermax=50):\n","\n","# Find the signal baseline using airPLS alghorithm\n","  # add_beginning=600\n","  # signal = np.insert(signal, 0, signal[0]*np.ones(add_beginning)).reshape(len(signal)+add_beginning,1)\n","  # base = airPLS(signal[:,0],lambda_=lambda_,porder=order,itermax=itermax).reshape(len(signal),1)\n","  # signal = signal[add_beginning:]\n","  # base = base[add_beginning:]\n","\n","  add=600\n","  s = np.r_[signal[add-1:0:-1],signal,signal[-2:-add-1:-1]]\n","  b = airPLS(s,lambda_=lambda_,porder=order,itermax=itermax)\n","  signal = s[add-1:-add+1]\n","  base = b[add-1:-add+1]\n","\n","# Remove the begining of the signal baseline\n","  signal = (signal - base)\n","\n","  return signal, base"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9-wm94jJBi3"},"source":["def standardize_signal(signal):\n","\n","  z_signal = (signal - np.nanmedian(signal)) / np.nanstd(signal)\n","\n","  return z_signal"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cKnY0hyitk_v"},"source":["airPLS algorithm"]},{"cell_type":"code","metadata":{"id":"l8re-Cp2tp4R"},"source":["'''\n","airPLS.py Copyright 2014 Renato Lombardo - renato.lombardo@unipa.it\n","Baseline correction using adaptive iteratively reweighted penalized least squares\n","\n","This program is a translation in python of the R source code of airPLS version 2.0\n","by Yizeng Liang and Zhang Zhimin - https://code.google.com/p/airpls\n","Reference:\n","Z.-M. Zhang, S. Chen, and Y.-Z. Liang, Baseline correction using adaptive iteratively reweighted penalized least squares. Analyst 135 (5), 1138-1146 (2010).\n","\n","Description from the original documentation:\n","\n","Baseline drift always blurs or even swamps signals and deteriorates analytical results, particularly in multivariate analysis.  It is necessary to correct baseline drift to perform further data analysis. Simple or modified polynomial fitting has been found to be effective in some extent. However, this method requires user intervention and prone to variability especially in low signal-to-noise ratio environments. The proposed adaptive iteratively reweighted Penalized Least Squares (airPLS) algorithm doesn't require any user intervention and prior information, such as detected peaks. It iteratively changes weights of sum squares errors (SSE) between the fitted baseline and original signals, and the weights of SSE are obtained adaptively using between previously fitted baseline and original signals. This baseline estimator is general, fast and flexible in fitting baseline.\n","\n","\n","LICENCE\n","This program is free software: you can redistribute it and/or modify\n","it under the terms of the GNU Lesser General Public License as published by\n","the Free Software Foundation, either version 3 of the License, or\n","(at your option) any later version.\n","\n","This program is distributed in the hope that it will be useful,\n","but WITHOUT ANY WARRANTY; without even the implied warranty of\n","MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","GNU Lesser General Public License for more details.\n","\n","You should have received a copy of the GNU Lesser General Public License\n","along with this program.  If not, see <http://www.gnu.org/licenses/>\n","'''\n","\n","import numpy as np\n","from scipy.sparse import csc_matrix, eye, diags\n","from scipy.sparse.linalg import spsolve\n","\n","def WhittakerSmooth(x,w,lambda_,differences=1):\n","    '''\n","    Penalized least squares algorithm for background fitting\n","    \n","    input\n","        x: input data (i.e. chromatogram of spectrum)\n","        w: binary masks (value of the mask is zero if a point belongs to peaks and one otherwise)\n","        lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background\n","        differences: integer indicating the order of the difference of penalties\n","    \n","    output\n","        the fitted background vector\n","    '''\n","    X=np.matrix(x)\n","    m=X.size\n","    #i=np.arange(0,m)\n","    E=eye(m,format='csc')\n","    D=E[1:]-E[:-1] # numpy.diff() does not work with sparse matrix. This is a workaround.\n","    W=diags(w,0,shape=(m,m))\n","    A=csc_matrix(W+(lambda_*D.T*D))\n","    B=csc_matrix(W*X.T)\n","    background=spsolve(A,B)\n","    return np.array(background)\n","\n","def airPLS(x, lambda_=100, porder=1, itermax=15):\n","    '''\n","    Adaptive iteratively reweighted penalized least squares for baseline fitting\n","    \n","    input\n","        x: input data (i.e. chromatogram of spectrum)\n","        lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background, z\n","        porder: adaptive iteratively reweighted penalized least squares for baseline fitting\n","    \n","    output\n","        the fitted background vector\n","    '''\n","    m=x.shape[0]\n","    w=np.ones(m)\n","    for i in range(1,itermax+1):\n","        z=WhittakerSmooth(x,w,lambda_, porder)\n","        d=x-z\n","        dssn=np.abs(d[d<0].sum())\n","        if(dssn<0.001*(abs(x)).sum() or i==itermax):\n","            if(i==itermax): print('WARING max iteration reached!')\n","            break\n","        w[d>=0]=0 # d>0 means that this point is part of a peak, so its weight is set to 0 in order to ignore it\n","        w[d<0]=np.exp(i*np.abs(d[d<0])/dssn)\n","        w[0]=np.exp(i*(d[d<0]).max()/dssn) \n","        w[-1]=w[0]\n","    return z\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCdbEzgS7Eo1"},"source":["def plot_raw(raw_signal,raw_reference,signal,reference,s_base,r_base,\n","            time_=None,events=None,measurements=None,\n","            figtitle=None,figsize=(22, 13),\n","            save=False,save_path='',image_format='.pdf'):\n","\n","  if time_ is None:\n","    time_ = range(len(raw_signal))\n","\n","  if (measurements is None) or arebinary(measurements):\n","   # Create figure\n","    fig, axs = plt.subplots(2,2,figsize=figsize)\n","    axs = axs.ravel()\n","   # Plot recordings\n","    axs[0].plot(time_,raw_signal, color='blue', linewidth=1.5)\n","    axs[0].plot(time_,s_base, color='black', linewidth=1.5)\n","    axs[0].set_ylabel('signal', fontsize='x-large', multialignment='center')\n","    axs[1].plot(time_,signal, color='blue',linewidth=1.5)\n","\n","    axs[2].plot(time_,raw_reference, color='purple', linewidth=1.5)\n","    axs[2].plot(time_,r_base, color='black', linewidth=1.5)\n","    axs[2].set_ylabel('reference', fontsize='x-large', multialignment='center')\n","    axs[3].plot(time_,reference, color='purple',linewidth=1.5)\n","\n","    axs[2].set_xlabel('time', fontsize='x-large', multialignment='center')\n","    axs[3].set_xlabel('time', fontsize='x-large', multialignment='center')\n","\n","   # Plot events\n","    if events is not None:\n","      cmap = get_cmap(len(events))\n","      for k,key in enumerate(events): # plot all events\n","      # if it's empty\n","        if len(events[key])==0:\n","          pass\n","        else:\n","          for ax in axs:\n","          # one occurance event\n","            if events[key].shape[1]==1:\n","              for event in events[key]:\n","                ax.axvline(event,linewidth=1,color=cmap(k),label=key)\n","          # event with onset and offset     \n","            elif events[key].shape[1]==2:\n","              for event0,event1 in events[key]:\n","                ax.axvspan(event0,event1,alpha=0.3,color=cmap(k),label=key)\n","   # X-ticks\n","    for ax in axs:\n","      ax.set_xlim([0,max(time_)])\n","      ax.tick_params(labelsize='large')\n","   # Legend\n","    for ax in axs:    \n","      handles, labels = ax.get_legend_handles_labels()\n","      by_label = OrderedDict(zip(labels, handles))\n","      ax.legend(by_label.values(), by_label.keys(), prop={'size': 'small'})\n","  \n","   # Title\n","    if figtitle is not None:\n","      fig.suptitle(figtitle, fontsize='xx-large')\n","    \n","   # Save figure\n","    if save:\n","      imgname = figtitle.replace(' ','_') + '_raw' + image_format\n","      fig.savefig(save_path+imgname)\n","\n","  else:\n","    for measure in measurements:\n","      if not isbinary(measurements[measure]['values']):\n","       # Create figure\n","        fig, axs = plt.subplots(2,2,figsize=figsize)\n","        axs = axs.ravel()\n","       # Plot recordings\n","        axs[0].plot(time_,raw_signal, color='blue', linewidth=1.5)\n","        axs[0].plot(time_,s_base, color='black', linewidth=1.5)\n","        axs[0].set_ylabel('signal', fontsize='x-large', multialignment='center')\n","\n","        axs[1].plot(time_,signal, color='blue',linewidth=1.5)\n","\n","        axs[2].plot(time_,raw_reference, color='purple', linewidth=1.5)\n","        axs[2].plot(time_,r_base, color='black', linewidth=1.5)\n","        axs[2].set_ylabel('reference', fontsize='x-large', multialignment='center')\n","        axs[2].set_xlabel('time', fontsize='x-large', multialignment='center')\n","        \n","        axs[3].plot(time_,reference, color='purple',linewidth=1.5)      \n","        axs[3].set_xlabel('time', fontsize='x-large', multialignment='center')\n","\n","       # Plot events\n","        cmap = get_cmap(len(events))\n","        for k,key in enumerate(events): # plot all events\n","         # if it's empty\n","          if len(events[key])==0:\n","            pass\n","          else:\n","            for ax in axs:\n","            # one occurance event\n","              if events[key].shape[1]==1:\n","                for event in events[key]:\n","                  ax.axvline(event,linewidth=1,color=cmap(k),label=key)\n","            # event with onset and offset     \n","              elif events[key].shape[1]==2:\n","                for event0,event1 in events[key]:\n","                  ax.axvspan(event0,event1,alpha=0.3,color=cmap(k),label=key)\n","      # Plot continious measurements\n","        if not np.array_equal(measurements[measure]['values'], measurements[measure]['values'].astype(bool)):\n","          for ax in axs:\n","            ax_m = ax.twinx()\n","            ax_m.plot(measurements[measure]['time'], measurements[measure]['values'], color='black',label=key)\n","            ax_m.set_ylabel(measure,fontsize='x-large',multialignment='center',color='black')\n","            ax_m.tick_params('y', colors='black')\n","            m_max = np.nanmax(measurements[measure]['values'])\n","            m_min = np.nanmin(measurements[measure]['values'])\n","            ax_m.set_ylim([m_min, m_max + (m_max-m_min)]) # plot on the bottom half\n","            ax.set_zorder(ax_m.get_zorder()+1) # put ax in front of ax_m\n","            ax.patch.set_visible(False) # hide the 'canvas'\n","      # X-ticks\n","        for ax in axs:\n","          ax.set_xlim([0,max(time_)])\n","          ax.tick_params(labelsize='large')\n","      # Legend\n","        for ax in axs:    \n","          handles, labels = ax.get_legend_handles_labels()\n","          by_label = OrderedDict(zip(labels, handles))\n","          ax.legend(by_label.values(), by_label.keys(), prop={'size': 'small'})   \n","      # Title\n","        if figtitle is not None:\n","          fig.suptitle(figtitle, fontsize='xx-large')\n","        \n","      # Save figure\n","        if save:\n","          if figtitle is None:\n","            imgname = 'raw' + image_format\n","          else:\n","            imgname = figtitle.replace(' ','_') + '_' + measure + '_raw' + image_format\n","          fig.savefig(save_path+imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHHD5Nsnl4Wj"},"source":["### Fit and align calcium-independent signal to calcium dependent"]},{"cell_type":"code","metadata":{"id":"VRsUbiwAKFiF"},"source":["def fit_signal(signal, reference, model='RANSAC'):\n","\n","  i0 = np.max(np.argwhere(np.isnan(signal)))\n","  signal = signal[i0+1:]\n","  reference = reference[i0+1:]\n","\n","  signal = np.array(signal).reshape(len(signal),1)\n","  reference = np.array(reference).reshape(len(reference),1)\n","\n","# Positive linear regression\n","  if model == 'RANSAC':\n","    from sklearn.linear_model import RANSACRegressor\n","    lin = RANSACRegressor(max_trials=1000,random_state=9999)\n","  elif model == 'Lasso':\n","    from sklearn.linear_model import Lasso\n","    lin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n","                positive=True, random_state=9999, selection='random')\n","\n","  lin.fit(reference, signal)\n","  reference_fitted = lin.predict(reference)\n","  reference_fitted = reference_fitted.reshape(len(reference_fitted),)\n","\n","  a = np.empty((i0+1,))\n","  a[:] = np.nan   \n","  reference_fitted = np.r_[a,reference_fitted]\n","      \n","  return reference_fitted"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLeqBM-nbJYT"},"source":["def plot_fit(signal,reference,reference_fitted,\n","             figtitle=None,figsize=(15,13),save=False,save_path='',image_format='.pdf'):\n","  \n","  fig = plt.figure(figsize=figsize)\n","  ax = fig.add_subplot(111)\n","  ax.plot(reference,signal,'b.')\n","  ax.plot(reference,reference_fitted, 'r--',linewidth=1.5)\n","  ax.set_xlabel('reference', fontsize='x-large', multialignment='center')\n","  ax.set_ylabel('signal', fontsize='x-large', multialignment='center')\n","  ax.tick_params(labelsize='large')\n"," # Title\n","  if figtitle is not None:\n","    fig.suptitle(figtitle, fontsize='xx-large')\n","  \n","  # Save figure\n","  if save:\n","    if figtitle is None:\n","      imgname = 'fit' + image_format\n","    else:\n","      imgname = figtitle.replace(' ','_') + '_fit' + image_format\n","    fig.savefig(save_path+imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zORanmGATTJT"},"source":["def plot_aligned(signal,reference,time_=None,events=None,measurements=None,\n","                 figtitle=None,figsize=(20,13),save=False,save_path='',image_format='.pdf'):\n","  \n","  if time_ is None:\n","    time_ = range(len(signal))\n","\n","  if (measurements is None) or arebinary(measurements):\n","    fig = plt.figure(figsize=figsize)\n","    ax = fig.add_subplot(111)\n","   # Signal\n","    ax.plot(time_, signal, 'black' ,linewidth=1.5)\n","    ax.plot(time_, reference, 'purple',linewidth=1.5)\n","   # Events\n","    if events is not None:\n","      cmap = get_cmap(len(events))\n","      for k,key in enumerate(events): # plot all events\n","        if len(events[key])==0:\n","          pass\n","        # one occurance event\n","        elif events[key].shape[1]==1:\n","          for event in events[key]:\n","            ax.axvline(event,linewidth=1,color=cmap(k),label=key)\n","        # event with onset and offset     \n","        elif events[key].shape[1]==2:\n","          for event0,event1 in events[key]:\n","            ax.axvspan(event0,event1,alpha=0.3,color=cmap(k),label=key)\n","   # Params\n","    ax.set_xlabel('time', fontsize='x-large', multialignment='center')\n","    ax.set_ylabel('Intensity', fontsize='x-large', multialignment='center')\n","    ax.set_xlim([0,max(time_)])\n","    ax.tick_params(labelsize='x-large')\n","   # Legend    \n","    handles, labels = ax.get_legend_handles_labels()\n","    by_label = OrderedDict(zip(labels, handles))\n","    ax.legend(by_label.values(), by_label.keys(), prop={'size': 'medium'})\n","   # Title\n","    if figtitle is not None:\n","      fig.suptitle(figtitle, fontsize='xx-large')\n","    \n","   # Save figure\n","    if save:\n","      imgname = figtitle.replace(' ','_') +'_align' + image_format\n","      fig.savefig(save_path+imgname)\n","\n","\n","  else:\n","    for measure in measurements:\n","      if not isbinary(measurements[measure]['values']):\n","        fig = plt.figure(figsize=figsize)\n","        ax = fig.add_subplot(111)\n","      # Signal\n","        ax.plot(time_, signal, 'black' ,linewidth=1.5)\n","        ax.plot(time_, reference, 'purple',linewidth=1.5)\n","      # Events\n","        cmap = get_cmap(len(events))\n","        for k,key in enumerate(events): # plot all events\n","          if len(events[key])==0:\n","            pass\n","         # one occurance event\n","          elif events[key].shape[1]==1:\n","            for event in events[key]:\n","              ax.axvline(event,linewidth=1,color=cmap(k),label=key)\n","         # event with onset and offset     \n","          elif events[key].shape[1]==2:\n","            for event0,event1 in events[key]:\n","              ax.axvspan(event0,event1,alpha=0.3,color=cmap(k),label=key)\n","      # Measurements\n","        ax_m = ax.twinx()\n","        ax_m.plot(measurements[measure]['time'], measurements[measure]['values'], color=cmap(k),label=key)\n","        ax_m.set_ylabel(measure,fontsize='x-large',multialignment='center',color=cmap(k))\n","        ax_m.tick_params('y', colors=cmap(k))\n","        m_max = np.nanmax(measurements[measure]['values'])\n","        m_min = np.nanmin(measurements[measure]['values'])\n","        ax_m.set_ylim([m_min, m_max + (m_max-m_min)]) # plot on the bottom half\n","        ax.set_zorder(ax_m.get_zorder()+1) # put ax in front of ax_e\n","        ax.patch.set_visible(False) # hide the 'canvas'\n","      # Params\n","        ax.set_xlabel('time', fontsize='x-large', multialignment='center')\n","        ax.set_ylabel('Intensity', fontsize='x-large', multialignment='center')\n","        ax.set_xlim([0,max(time_)])\n","        ax.tick_params(labelsize='x-large')\n","      # Legend    \n","        handles, labels = ax.get_legend_handles_labels()\n","        by_label = OrderedDict(zip(labels, handles))\n","        ax.legend(by_label.values(), by_label.keys(), prop={'size': 'medium'})\n","      # Title\n","        if figtitle is not None:\n","          fig.suptitle(figtitle, fontsize='xx-large')\n","        \n","      # Save figure\n","        if save:\n","          if figtitle is None:\n","            imgname = 'align' + image_format\n","          else:\n","            imgname = figtitle.replace(' ','_') + '_'+ measure +'_align' + image_format\n","          fig.savefig(save_path+imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kjv9sM8fm0B9"},"source":["### Calculate z dFF"]},{"cell_type":"code","metadata":{"id":"1mgAC2IDc7Hd"},"source":["def calculate_dff(signal,reference,standardized=True):\n","\n","  if standardized:\n","    dFF = signal - reference\n","  else:\n","    dFF = (signal - reference) / reference\n","\n","  dFF = standardize_signal(dFF)\n","\n","  return dFF  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_uLFveRdWZG"},"source":["def plot_dff(dFF,time_=None,events=None,measurements=None,\n","            figtitle=None,figsize=(20,13),save=False,save_path='',image_format='.pdf'):\n","\n","  if time_ is None:\n","    time_ = range(len(dFF))\n","\n","  ymin = np.nanmin([-3, np.nanmin(dFF)])\n","  ymax = np.nanmax([3, np.nanmax(dFF)])\n","\n","  if (measurements is None) or arebinary(measurements):\n","   # Figure\n","    fig = plt.figure(figsize=figsize)\n","    ax = fig.add_subplot(111)\n","   # Signal\n","    ax.plot(time_, dFF, 'black' ,linewidth=1.5)\n","   # Events\n","    if events is not None:\n","      cmap = get_cmap(len(events))\n","      for k,key in enumerate(events): # plot all events\n","        if len(events[key])==0:\n","          pass\n","      # one occurance event\n","        elif events[key].shape[1]==1:\n","          for event in events[key]:\n","            ax.axvline(event,linewidth=1,color=cmap(k),label=key)\n","      # event with onset and offset     \n","        elif events[key].shape[1]==2:\n","          for event0,event1 in events[key]:\n","            ax.axvspan(event0,event1,alpha=0.3,color=cmap(k),label=key)\n","   # Params\n","    ax.set_xlabel('time', fontsize='x-large', multialignment='center')\n","    ax.set_ylabel('dF/F', fontsize='x-large', multialignment='center')\n","    ax.set_xlim([0,max(time_)])\n","    ax.set_ylim([ymin, ymax])\n","    ax.tick_params(labelsize='large')\n","   # Legend    \n","    handles, labels = ax.get_legend_handles_labels()\n","    by_label = OrderedDict(zip(labels, handles))\n","    ax.legend(by_label.values(), by_label.keys(), prop={'size': 'medium'})\n","   # Title\n","    if figtitle is not None:\n","      fig.suptitle(figtitle, fontsize='xx-large')\n","\n","   # Save figure\n","    if save:\n","      imgname = figtitle.replace(' ','_') +'_dFF' + image_format\n","      fig.savefig(save_path+imgname)\n","\n","  else:\n","    for measure in measurements:\n","      if not isbinary(measurements[measure]['values']):\n","      # Figure\n","        fig = plt.figure(figsize=figsize)\n","        ax = fig.add_subplot(111)\n","      # Signal\n","        ax.plot(time_, dFF, 'black' ,linewidth=1.5)\n","      # Events\n","        cmap = get_cmap(len(events))\n","        for k,key in enumerate(events): # plot all events\n","          if len(events[key])==0:\n","            pass\n","        # one occurance event\n","          elif events[key].shape[1]==1:\n","            for event in events[key]:\n","              ax.axvline(event,linewidth=1,color=cmap(k),label=key)\n","        # event with onset and offset     \n","          elif events[key].shape[1]==2:\n","            for event0,event1 in events[key]:\n","              ax.axvspan(event0,event1,alpha=0.3,color=cmap(k),label=key)\n","      # Measurements\n","        ax_m = ax.twinx()\n","        ax_m.plot(measurements[measure]['time'], measurements[measure]['values'], color=cmap(k),label=key)\n","        ax_m.set_ylabel(measure,fontsize='x-large',multialignment='center',color=cmap(k))\n","        ax_m.tick_params('y', colors=cmap(k))\n","        m_max = np.nanmax(measurements[measure]['values'])\n","        m_min = np.nanmin(measurements[measure]['values'])\n","        ax_m.set_ylim([m_min, m_max + (m_max-m_min)]) # plot on the bottom half\n","        ax.set_zorder(ax_m.get_zorder()+1) # put ax in front of ax_e\n","        ax.patch.set_visible(False) # hide the 'canvas'\n","      # Params\n","        ax.set_xlabel('time', fontsize='x-large', multialignment='center')\n","        ax.set_ylabel('dF/F', fontsize='x-large', multialignment='center')\n","        ax.set_xlim([0,max(time_)])\n","        ax.set_ylim([ymin, ymax])\n","        ax.tick_params(labelsize='large')\n","      # Legend    \n","        handles, labels = ax.get_legend_handles_labels()\n","        by_label = OrderedDict(zip(labels, handles))\n","        ax.legend(by_label.values(), by_label.keys(), prop={'size': 'medium'})\n","      # Title\n","        if figtitle is not None:\n","          fig.suptitle(figtitle, fontsize='xx-large')\n","\n","      # Save figure\n","        if save:\n","          if figtitle is None:\n","            imgname = 'dFF' + image_format\n","          else:\n","            imgname = figtitle.replace(' ','_') + '_'+ measure +'_dFF' + image_format\n","          fig.savefig(save_path+imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6OpwwgDinYc6"},"source":["### Perievent data"]},{"cell_type":"code","metadata":{"id":"08tPuuIiAU3P"},"source":["def create_perievents(signal,time_,event,window=[-5.0,5.0],dur=None,iei=None,avg_win=None):\n","\n","  period = find_avg_period(time_, time_format='total seconds')\n","\n"," # Remove events at the beginning and end of test that less than win \n","  event = event[np.all(event > abs(window[0]), axis=1)]\n","  event = event[np.all(event < max(time_)-window[1], axis=1)]\n","\n"," # Events with one occurence ---------------------------------------------------\n","  if event.shape[1]==1:\n","    Array = []\n","    for e in event:\n","      s_event = chunk_signal(signal,e,time_,window)\n","      if avg_win is not None:\n","        s_event_mean = (s_event[int((-window[0]+avg_win[0])/period):int((-window[0]+avg_win[1])/period)]).mean()\n","        s_event = s_event - s_event_mean\n","      Array.append(s_event)    \n","    Array = np.array(Array).squeeze()\n","    if Array.ndim == 1:\n","      Array = Array.reshape(1,len(Array))\n","    Array = Array[~np.isnan(Array).any(axis=1)]\n","\n","    Perievents = {'onset': Array}\n","\n"," # Events with onset and offset ------------------------------------------------\n","  elif event.shape[1]==2:\n","\n"," # Remove short intervals and durations\n","    event = adjust_intervals_durations(event, iei, dur)\n","      \n","   # Create Perievent Arrays\n","   # Initialize Arrays\n","    Array_onset = []\n","    Array_offset = []\n","   # Loop through all onsets and offsets\n","    for e0,e1 in event:\n","      s_onset = chunk_signal(signal,e0,time_,window)\n","      s_offset = chunk_signal(signal,e1,time_,window)\n","     # Normalize signals to signals in avg_win\n","      if avg_win is not None:\n","        s_event_mean = (s_onset[int((-window[0]+avg_win[0])/period):int((-window[0]+avg_win[1])/period)]).mean()\n","        s_onset = s_onset - s_event_mean\n","        s_offset = s_offset - s_event_mean\n","     # Append to arrays   \n","      Array_onset.append(s_onset)\n","      Array_offset.append(s_offset)\n","   # Squeeze to 2D arrays   \n","    Array_onset = np.array(Array_onset).squeeze()\n","    Array_offset = np.array(Array_offset).squeeze()\n","   # Reshape Arrays if squeezed to 1D \n","    if Array_onset.ndim == 1:\n","      Array_onset = Array_onset.reshape(1,len(Array_onset))\n","      Array_offset = Array_offset.reshape(1,len(Array_offset))\n","   # Remove elements with nans   \n","    Array_onset = Array_onset[~np.isnan(Array_onset).any(axis=1)]\n","    Array_offset = Array_offset[~np.isnan(Array_offset).any(axis=1)]\n","\n","    Perievents = {'onset': Array_onset,\n","                 'offset': Array_offset}\n","\n","  return Perievents"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1U3HD5RdQBYQ"},"source":["def chunk_signal(signal, t0, t, w):\n","\n","  idx = find_idx(t0, t, 'total seconds')\n","\n","  period = find_avg_period(t, 'total seconds')\n","\n","  i0 = idx + int(w[0]/period - 1/2)\n","  i1 = idx + int(w[1]/period + 1/2) + 1\n","\n","  chunk = signal[i0:i1]\n","\n","  return chunk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxCTbYi0AbSh"},"source":["def create_centered_time_vector(period=0.1,window=[-5.0,5.0]):\n","\n","  t_pre = np.arange(-period,window[0]-period/2,-period)\n","  t_post = np.arange(0,window[1]+period/2,period)\n","  t = np.concatenate([t_pre[-1::-1],t_post])\n","\n","  return t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"55-pyPDsdPaI"},"source":["def plot_perievents(Array,period=0.10,\n","                    Array1=None,period1=None,\n","                    window=[-5.0,5.0],color='green',\n","                    figtitle=None,figsize=None,\n","                    save=False,save_path='',image_format='.pdf'):\n","\n","  Mean = {}\n","  Error = {}\n","  for key in Array:\n","    Mean[key] = np.nanmean(Array[key],axis=0)\n","    Error[key] = np.nanstd(Array[key],axis=0) / np.sqrt(Array[key].shape[0])\n","  \n","  ymax = 2\n","  ymin = -2\n","  for key in Array:\n","    ymax = max(ymax,1.1*Array[key].max())\n","    ymin = min(ymin,1.1*Array[key].min())\n","\n","  ts = create_centered_time_vector(period,window)\n","\n","  if Array1 is not None:\n","    Mean1 = {}\n","    Error1 = {}\n","    for key in Array1:\n","      Mean1[key] = np.nanmean(Array1[key],axis=0)\n","      Error1[key] = np.nanstd(Array1[key],axis=0) / np.sqrt(Array1[key].shape[0])\n","\n","    ymax1 = max( [Array1[key1].max() for key1 in Array1.keys()] )\n","    ymin1 = min( [Array1[key1].min() for key1 in Array1.keys()] )\n","    std1 = np.nanstd( [np.nanstd(Array1[key1]) for key1 in Array1.keys()] )\n","\n","    ts1 = create_centered_time_vector(period1,window)\n","\n","  if figsize is None:\n","    if len(Array) == 1:\n","      figsize = (12,10)\n","    else:\n","      figsize = (20,10)\n","\n","  from matplotlib import gridspec\n","\n","  fig = plt.figure(figsize=figsize)\n","  gs = gridspec.GridSpec(1, len(Array))\n","  for i,key in enumerate(Array):\n","    ax = fig.add_subplot(gs[i])  \n","    ax.set_title(key, fontsize='xx-large')\n","    ax.plot(ts,Array[key].T,color=color,alpha=0.5,linewidth=1)\n","    ax.plot(ts,Mean[key],color=color,linewidth=2)\n","    ax.fill_between(ts, Mean[key]-Error[key],Mean[key]+Error[key],\n","                    alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","    ax.axvline(0,linestyle='--',color='black',linewidth=1.5)\n","    ax.set_xlabel('time', fontsize='xx-large', multialignment='center')\n","    ax.set_ylabel('z dF/F', fontsize='xx-large', multialignment='center')\n","    ax.set_ylim([ymin,ymax])\n","    ax.set_xlim(window)\n","    ax.tick_params(labelsize='x-large')\n","    if Array1 is not None:\n","      ax_m = ax.twinx()\n","      ax_m.plot(ts1,Array1[key].T,color='black',alpha=0.5,linewidth=1)\n","      ax_m.plot(ts1,Mean1[key],color='black',linewidth=2)\n","      ax_m.fill_between(ts1, Mean1[key]-Error1[key], Mean1[key]+Error1[key],\n","                    alpha=0.3,edgecolor='black',facecolor='black',linewidth=0)\n","      ax_m.set_ylim([ymin1, ymax1 + std1]) # plot on the bottom half\n","      ax.set_zorder(ax_m.get_zorder()+1) # put ax in front of ax_m\n","      ax.patch.set_visible(False) # hide the 'canvas'\n","  # Title\n","  if figtitle is not None:\n","    fig.suptitle(figtitle, fontsize='xx-large')\n","\n"," # Save figure\n","  if save:\n","    if figtitle is None:\n","      imgname = 'mean' + image_format\n","    else:\n","      imgname = figtitle.replace(' ','_') +'_mean' + image_format\n","    fig.savefig(save_path+imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cjVXjmTxQYH5"},"source":["# OS helper functions"]},{"cell_type":"markdown","metadata":{"id":"W6y1l6h6osL8"},"source":["### Find file in the list of files by part of the name"]},{"cell_type":"code","metadata":{"id":"1Xgmlaulo6UK"},"source":["def contains(name, strings):\n","  answer = True\n","  for string in strings:\n","    if string not in name:\n","      answer = False\n","  return answer\n","\n","\n","def find_files(folder,strings):\n","\n","    file_list = os.listdir(folder)\n","    files = []\n","    \n","    for file_name in file_list:\n","      if contains(file_name,strings):\n","        files.append(file_name)\n","    \n","    return files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jYPC6PaLQOe7"},"source":["### Create folder if it doesn't exist"]},{"cell_type":"code","metadata":{"id":"D6xFsI8ANMw1"},"source":["def create_folder(new_folder):\n","  if not os.path.exists(new_folder):\n","    os.mkdir(new_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EwS0b_QyRcVm"},"source":["# Time helper functions"]},{"cell_type":"markdown","metadata":{"id":"TxaRCTaDdNJi"},"source":["### Create time of format 'HH:MM:SS.ms' from list of hours, minutes, seconds, andmiliseconds."]},{"cell_type":"code","metadata":{"id":"iFOsmYj5dMZb"},"source":["def create_realtime(hh,mm,ss,ms):\n","  \n"," # Hours\n","  if hh is not list:\n","    hh = hh*np.ones(len(mm),dtype=int)\n","    dif_mm = np.diff(mm)\n","    hour_change = [i+1 for i in range(len(dif_mm)) if dif_mm[i]<0]\n","    if len(hour_change) != 0:\n","      for i in hour_change:\n","        hh[i:] = [h+1 for h in hh[i:]]\n","    hh = [str(int(h)) for h in hh]\n","\n"," # Minutes\n","  for i in range(len(mm)):\n","    if mm[i]<10:\n","      mm[i] = '0'+str(int(mm[i]))\n","    else:\n","      mm[i] = str(int(mm[i]))\n"," \n"," # Seconds\n","  for i in range(len(ss)):\n","    if ss[i]<10:\n","      ss[i] = '0'+str(int(ss[i]))\n","    else:\n","      ss[i] = str(int(ss[i]))\n"," \n"," # Miliseconds\n","  for i in range(len(ms)):\n","    if ms[i]<10:\n","      ms[i] = '00'+str(int(ms[i]))\n","    elif ms[i]<100:\n","      ms[i] = '0'+str(int(ms[i]))\n","    else:\n","      ms[i] = str(int(ms[i]))\n","\n","  realtime = [h+':'+m+':'+s+'.'+x for h,m,s,x in zip(hh,mm,ss,ms)]\n","\n","  return realtime"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0DwnwPjRhm6"},"source":["### Transform real time 'HH:MM:SS.ms' to total seconds"]},{"cell_type":"code","metadata":{"id":"6CmRPSYrYuH1"},"source":["def time_to_seconds(t, t0=None):\n","\n","  if t0 is not None:\n","    t = np.array([(pd.Timedelta(x)-pd.Timedelta(t0)).total_seconds() for x in t])\n","  else:\n","    t = np.array([pd.Timedelta(x).total_seconds() for x in t])\n","\n","  return t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c4yCzfkIR0wC"},"source":["### Find avereage period of recording"]},{"cell_type":"code","metadata":{"id":"lSfmiLFKIlnA"},"source":["def find_avg_period(t, time_format='total seconds'):\n","\n","  if time_format=='real time':\n","    t = time_to_seconds(t, t[0])\n","\n","  dt = np.diff(t)\n","\n","  T = np.median(dt)\n","\n","  T = round(T,10)\n","\n","  return T"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9btxEByzR7CJ"},"source":["### Find index based on time"]},{"cell_type":"code","metadata":{"id":"ohvo3fktJCDb"},"source":["def find_idx(t, time_vector, time_format='total seconds'):\n","\n","  if time_format == 'real time':\n","    time_vector = np.array([(pd.Timedelta(t)-t0).total_seconds() for t in time_vector])\n","  \n","  elif time_format == 'total seconds':\n","    time_vector = np.array(time_vector)\n","\n","  idx = (np.abs(time_vector-t)).argmin()\n","\n","  return idx "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"57iSo9aIQhX6"},"source":["# Behavior events helper functions"]},{"cell_type":"markdown","metadata":{"id":"PFg-9Jdk1gfv"},"source":["### Get vector of values from Med Associates file"]},{"cell_type":"code","metadata":{"id":"1hl47_U41dXb"},"source":["def values_from_medfile(file_name,letter):\n","\n","  import string\n","  med_letters = []\n","  for l in list(string.ascii_uppercase):\n","    med_letters.append(l+':')\n","\n","# Get info from the file  \n","  lines = []\n","  file = open(file_name, 'r')\n","  for line in file:\n","    lines.append(line.rstrip('\\n'))\n","  file.close()\n","\n","  if letter in ['File','Start Date','End Date','Subject','Experiment','Group','Box','Start Time','End Time','MSN']:\n","    for l in lines:\n","      if letter+':' in l:\n","        break\n","    return l.replace(letter+': ','')\n","\n","# Get the indecies of start and end lines\n","  start_line = ''\n","  end_line = ''\n","  for idx in range(13,len(lines)):\n","    if letter+':' in lines[idx]:\n","      start_line = idx\n","      break\n","  for idx in range(start_line+1,len(lines)):    \n","    if lines[idx][:2] in med_letters:\n","      end_line = idx\n","      break\n","  if end_line == '':\n","    end_line = len(lines)\n","\n","# Create a list of values\n","  values = []\n","  for idx in range(start_line,end_line):\n","    line = lines[idx]\n","    for letter in med_letters:\n","      if letter in line:\n","        line = line.replace(letter,'')\n","    line_elements = line.split(' ')\n","    for element in line_elements:\n","      if element != '' and ':' not in element:\n","        values.append(float(element)) \n","\n","  return(values)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0nn0JkXQ3I9P"},"source":["### Find onsets and offsets based on binary vector"]},{"cell_type":"code","metadata":{"id":"EiHX1Fzw3Ic7"},"source":["def event_onoffset(vector,time_=None,t0=None,time_format='total seconds'):\n","\n","  '''\n","  Finds event onsets and offsets based on the binary vector\n","  \n","  input\n","    vector: binary vector, where 1 means event was present and 0 - no event;\n","    time_: time, the same length as vector;\n","    t0: start time, should be in the same format as time_\n","    time_format: 'real time' is format of'HH:MM:SS.ms', \n","                 'total seconds' is a vector of numbers\n","\n","  output\n","    event: numpy array with first column with event onset and second with offset\n","  '''\n","\n","  # Transform the vector to numpy array\n","  vector = np.array(vector)\n","\n","  # Calculate the n-th discrete difference\n","  diff_v = np.diff(vector)\n","\n"," # Find event onset (==1) and offset (==-1)\n","  onset = [i+1 for i in range(len(diff_v)) if diff_v[i] > 0]\n","  offset = [i for i in range(len(diff_v)) if diff_v[i] < 0]\n","\n"," # Check if onset and offset are the same length and adjust\n","  if len(onset) < len(offset):\n","    onset = [0] + onset\n","  elif len(offset) < len(onset):\n","    offset = offset + [len(vector)-1] \n","  \n","  if time_ is not None:\n","   # Create list of time in total seconds if it was in the format of real time\n","    if time_format == 'real time':\n","      total_sec = time_to_seconds(time_,t0=t0)  \n","    elif time_format == 'total seconds':\n","      total_sec = list(time_)\n","      if t0 is not None:\n","        total_sec = [t-t0 for t in total_sec]\n","\n","   # Convert indices to time\n","    onset = [total_sec[i] for i in onset]\n","    offset = [total_sec[i] for i in offset] \n","\n"," # Reshape\n","  onset = np.array(onset).reshape(len(onset),1)\n","  offset = np.array(offset).reshape(len(offset),1)\n","\n"," # Concat onset and offsets to 2D numpy array\n","  event = np.concatenate([onset,offset],axis=1)\n","\n","  return event"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m0PxBqtjUEDH"},"source":["### Remove events with short inter event intervals and/or short duration"]},{"cell_type":"code","metadata":{"id":"PQBymXsd43Lr"},"source":["def adjust_intervals_durations(event, min_interval=None, min_duration=None):\n","\n","  if min_interval is not None:         \n","    onset = event[:,0]\n","    offset = event[:,1]\n","    intervals = np.array(onset[1:]) - np.array(offset[:-1])\n","    idx = np.array(np.where(intervals > min_interval)).squeeze()\n","    onset = np.append(onset[0],onset[idx+1])\n","    offset = np.append(offset[idx],offset[-1])\n","    event = np.concatenate([onset.reshape(len(onset),1),offset.reshape(len(offset),1)],axis=1)\n","\n","  if min_duration is not None:\n","    duration = event[:,1] - event[:,0]\n","    idx = np.array(np.where(duration > min_duration)).squeeze()\n","    event = event[idx]\n","\n","  if len(event.shape) == 1:\n","    event = event.reshape(1,2)\n","\n","  return event"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jj90oAZZyIux"},"source":["### Find speed from coordinates and time"]},{"cell_type":"code","metadata":{"id":"pNQ2JOZ7yOaZ"},"source":["def get_speed(x,y,t,smooth_filter=None,smooth_parameter=1):\n","\n","  v = np.zeros(len(x))\n","\n","  for i in range(len(x)):\n","    \n","    if i==0:\n","      i_next = i + 1\n","      i_prev = i\n","\n","    elif i==len(x)-1:\n","      i_next = i\n","      i_prev = i - 1\n","\n","    else:\n","      i_next = i + 1\n","      i_prev = i - 1\n","\n","    dl = np.sqrt((x[i_next]-x[i_prev])**2 + (y[i_next]-y[i_prev])**2)\n","    dt = abs(t[i_next]-t[i_prev])\n","    v[i] = dl / dt\n","\n"," # Smooth speed\n","  if smooth_filter is not None:\n","    T = find_average(t)\n","  if smooth_filter=='moving average':\n","    v = smooth_signal(v,window_len=int(smooth_parameter/T))\n","  if smooth_filter=='low-pass':\n","    v = butter_lowpass_filter(v, smooth_parameter, 1/T, order=10)\n","\n","  return v "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ih6nvzVZextN"},"source":["def remove_outliers(v,t,percentile=0.995):\n","  \n","  q = np.quantile(v,percentile)\n","  outliers = np.argwhere(v>q).squeeze()\n","  v = np.delete(v,outliers)\n","  t_new = np.delete(t,outliers)\n","\n","  if outliers[0]==0:\n","    v = np.insert(v,0,v[0])\n","    t_new = np.insert(t_new,0,t[0])\n","  \n","  if outliers[-1]==(t.size-1):\n","    v = np.insert(v,v.size,v[-1])\n","    t_new = np.insert(t_new,t_new.size,t[-1])\n","    \n","  return v,t_new"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"do8b0Z71Mv9y"},"source":["### Find immobility onsets and offsets"]},{"cell_type":"code","metadata":{"id":"lWQLpu9J4JXN"},"source":["def find_onoffset_immobility(movement,time_, min_duration=1, on_threshold=0.1, off_threshold=0.15,output='time'):\n","\n","  if np.isnan(movement).any():\n","    i = np.max(np.argwhere(np.isnan(movement)))+1\n","  else: i = 0\n","\n","  onset = []\n","  offset = []\n","\n","  while i < len(movement)-1:\n","\n","    if movement[i] < on_threshold:\n","      start = i\n","      t0 = time_[start]\n","      while time_[i] - t0 < min_duration:\n","        i += 1\n","        if i >= len(movement)-1:\n","          break\n","      \n","      if (movement[start:i] < on_threshold).all():\n","        if output=='time': onset.append(time_[start])\n","        elif output=='index': onset.append(start)\n","\n","        while movement[i] < off_threshold:\n","          i += 1\n","          if i >= len(movement)-1:\n","            break\n","\n","        if output=='time': offset.append(time_[i-1])\n","        elif output=='index': offset.append(i-1)\n","        \n","    i += 1 \n","\n"," # Adjust mobility onset\n","  T = find_avg_period(time_)\n","  win = int(round(min_duration/T))\n","  for i in range(len(offset)):\n","    if output=='time': i1 = find_idx(offset[i],time_)\n","    elif output=='index': i1 = offset[i]\n","    off = i1 - np.argmin(movement[i1:i1-win:-1])\n","    if output=='time': offset[i] = time_[off]\n","    elif output=='index': offset[i] = off\n","\n","  if output=='time' : intervals = np.array(onset[1:]) - np.array(offset[:-1])\n","  elif output=='index': intervals = np.array(time_[onset[1:]]) - np.array(time_[offset[:-1]])\n","  remove = [i for i in range(len(intervals)) if intervals[i] < min_duration]\n","  onset = np.delete(onset,[i+1 for i in remove])\n","  offset = np.delete(offset,remove) \n","\n","  immobility = np.array([onset,offset]).T\n","\n","  return immobility"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLmwjUtry7XY"},"source":["def convert_onoffset(onoff, end, start=0):\n","  if onoff[0,0] != start and onoff[-1,1] != end:\n","    offon = np.zeros((len(onoff)+1,2),dtype=onoff.dtype)\n","    offon[1:,0] = onoff[:,1]\n","    offon[:-1,1] = onoff[:,0]\n","    offon[0,0] = start\n","    offon[-1,1] = end\n","  if onoff[0,0] != start and onoff[-1,1] == end:\n","    offon = np.zeros(onoff.shape,dtype=onoff.dtype)\n","    offon[1:,0] = onoff[:-1,1]\n","    offon[:,1] = onoff[:,0]\n","    offon[0,0] = start\n","  if onoff[0,0] == start and onoff[-1,1] != end:\n","    offon = np.zeros(onoff.shape,dtype=onoff.dtype)\n","    offon[:,0] = onoff[:,1]\n","    offon[:-1,1] = onoff[1:,0]\n","    offon[-1,1] = end\n","  if onoff[0,0] == start and onoff[-1,1] == end:\n","    offon = np.zeros((len(onoff)-1,2),dtype=onoff.dtype)\n","    offon[:,0] = onoff[:-1,1]\n","    offon[:,1] = onoff[1:,0]\n","\n","  return offon"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UOLNC3luM0vL"},"source":["# Plot helper functions"]},{"cell_type":"markdown","metadata":{"id":"9sMG8y21nSa3"},"source":["### Make patch spines invisible"]},{"cell_type":"code","metadata":{"id":"-Qma66YCnXCZ"},"source":["def make_patch_spines_invisible(ax):\n","    ax.set_frame_on(True)\n","    ax.patch.set_visible(False)\n","    for sp in ax.spines.values():\n","        sp.set_visible(False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ohfbz2kSizL0"},"source":["### Plot colors"]},{"cell_type":"code","metadata":{"id":"u9i37YhXi5sr"},"source":["def get_cmap(n, name='gist_rainbow'):\n","    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n","    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n","    return mpl.colormaps.get_cmap(name).resampled(n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MmuLDF6J4yif"},"source":["### Plot means"]},{"cell_type":"code","metadata":{"id":"3Bn-_OOF3sKM"},"source":["def plot_means(array,T=0.1,w=[-5,5],auc=None,plot_type='individual traces',plot_event=None,\n","              title='',periods=['baseline', 'event'],figsize=(3.5,3),\n","              color='green',ylab='z-dF/F',xlim=[-5,5],ylim=[-1,5],yticks=None,\n","              array1=None,auc1=None,T1=0.1,title1='AUC',\n","              color1='magenta',ylab1='Mobility score',ylim1=[-1,1],yticks1=None,\n","              subplot_ratio=[5,2],save=False,imgname='means.pdf'):\n","  \n","  import seaborn as sns\n","  from matplotlib import gridspec\n","\n","  if plot_type in ['mean and SEM','mixed']:\n","    mean,error = calculate_mean_error(array)\n","    if auc is not None:\n","      auc_m,auc_e = calculate_mean_error(auc)\n","    if array1 is not None:\n","      mean1,error1 = calculate_mean_error(array1)\n","    if auc1 is not None:\n","      auc_m1,auc_e1 = calculate_mean_error(auc1)\n","\n","\n","  # Create time vector\n","  t = create_centered_time_vector(T,w)\n","\n","  fig = plt.figure(figsize=figsize)\n","  if auc is not None:\n","    gs = gridspec.GridSpec(1, 2, width_ratios=subplot_ratio)\n","    ax = fig.add_subplot(gs[0])\n","  else:\n","    ax = fig.add_subplot()\n","  ax.set_title(title,size='x-large')\n","  ax.set_ylabel(ylab,size='large')\n","  ax.set_xlabel('Time (s)',size='large')\n","  ax.patch.set_visible(False) \n","  ax.set_xlim(xlim)\n","  ax.set_ylim(ylim)\n","  if yticks is not None:\n","    ax.set_yticks(yticks)\n","  # Plot mean trace for each mouse\n","  sns.set(style=\"ticks\")\n","  sns.despine(ax=ax)\n","  if plot_type=='individual traces':\n","    for mouse in range(len(array)):\n","      sns.lineplot(t,array[mouse,:],color=color,ax=ax)\n","  if plot_type=='mean and SEM':\n","    ax.plot(t,mean,color=color)\n","    ax.fill_between(t,mean-error,mean+error,alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","  elif plot_type=='mixed':\n","    for mouse in range(len(array)):\n","      sns.lineplot(t,array[mouse,:],color='black',alpha=0.2,ax=ax)\n","    ax.plot(t,mean,color=color)\n","    ax.fill_between(t,mean-error,mean+error,alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","\n","  if plot_event is not None:\n","    if len(plot_event) == 2:\n","      ax.axvspan(plot_event[0],plot_event[1],color='blue',alpha=0.2)\n","  else:\n","    ax.axvline(0,linestyle='--',color='black')\n","\n","  if array1 is not None:\n","    ax.tick_params(axis='y',colors=color)\n","    ax.yaxis.label.set_color(color)\n","    ax.spines['left'].set_color(color)\n","\n","  # Plot values for area under the curve\n","  if auc is not None:\n","    x = range(1,2*len(periods),2)\n","    ax1 = fig.add_subplot(gs[1])\n","    sns.despine(ax=ax1)\n","    if plot_type=='individual traces':\n","      for mouse in range(len(auc)):\n","        sns.lineplot(x,auc[mouse,:],color=color,ax=ax1)\n","    if plot_type=='mean and SEM':\n","      ax1.errorbar(x,auc_m,auc_e,color=color)\n","    if plot_type=='mixed':\n","      ax1.plot(x,auc.T,color='black',alpha=0.2)\n","      ax1.errorbar(x,auc_m.T,auc_e.T,color=color)\n","    ax1.set_xticklabels(periods, rotation=50)\n","    ax1.xaxis.set_ticks(range(1,2*len(periods),2))\n","    ax1.set_xlim([0,2*len(periods)])\n","    ax1.set_ylim(ylim)\n","    if yticks is not None:\n","      ax1.set_yticks(yticks)\n","    ax1.set_yticklabels([])\n","    for label in ax1.get_xticklabels():\n","      label.set_horizontalalignment('center')\n","    if auc1 is not None:\n","      ax1.tick_params(axis='y',colors=color)\n","      ax1.yaxis.label.set_color(color)\n","      ax1.spines['left'].set_color(color)\n","    \n","\n","  # Plot a second measure  \n","  if array1 is not None:\n","    # Create time vector for the second measure\n","    t1 = create_centered_time_vector(T1,w)\n","    # Plot means for each animal\n","    ax2 = ax.twinx()\n","    sns.despine(ax=ax2,right=False)\n","    if plot_type=='individual traces':\n","      for mouse in range(len(array1)):   \n","        sns.lineplot(t1,array1[mouse,:],color=color1,ax=ax2)\n","    elif plot_type=='mean and SEM':\n","      ax2.plot(t1,mean1,color=color1)\n","      ax2.fill_between(t1,mean1-error1,mean1+error1,alpha=0.3,edgecolor=color1,facecolor=color1,linewidth=0)\n","    elif plot_type=='mixed':\n","      for mouse in range(len(array1)):\n","        sns.lineplot(t1,array1[mouse,:],color='black',alpha=0.2,ax=ax2)\n","      ax2.plot(t1,mean1,color=color1)\n","      ax2.fill_between(t1,mean1-error1,mean1+error1,alpha=0.3,edgecolor=color1,facecolor=color1,linewidth=0)\n","    ax2.set_ylim(ylim1)\n","    if yticks1 is not None:\n","      ax2.set_yticks(yticks1)\n","    ax2.tick_params(axis='y',colors=color1)\n","    ax2.yaxis.label.set_color(color1)\n","    ax2.spines['right'].set_color(color1)\n","    ax2.spines['left'].set_visible(False)\n","    if auc1 is None:\n","      ax2.set_ylabel(ylab1,color=color1,size='large')\n","    else:\n","      ax2.set_yticklabels([])\n","\n","\n","  if auc1 is not None:\n","    ax3 = ax1.twinx()\n","    sns.despine(ax=ax1,right=False)\n","    if plot_type=='individual traces':\n","      for mouse in range(len(auc1)):\n","        sns.lineplot(x,auc1[mouse,:],color=color1,ax=ax3)\n","    if plot_type=='mean and SEM':\n","      ax3.errorbar(x,auc_m1,auc_e1,color=color1)\n","    if plot_type=='mixed':\n","      ax3.plot(x,auc1.T,color='black',alpha=0.2)\n","      ax3.errorbar(x,auc_m1.T,auc_e1.T,color=color1)\n","    sns.despine(ax=ax3,right=False)\n","    ax3.set_ylim(ylim1)\n","    if yticks1 is not None:\n","      ax3.set_yticks(yticks1)\n","    ax3.tick_params(axis='y',colors=color1)\n","    ax3.yaxis.label.set_color(color1)\n","    ax3.spines['right'].set_color(color1)\n","    ax3.spines['left'].set_visible(False)\n","    ax3.set_ylabel(ylab1,color=color1,size='large')\n","    for label in ax3.get_xticklabels():\n","      label.set_horizontalalignment('center')\n","    \n","  \n","  plt.tight_layout()\n","\n","  if save:\n","    fig.savefig(imgname)\n","\n","  return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWfLK7cwiNuv"},"source":["def calculate_mean_error(data,error='SEM',confidence=0.95):\n","\n","  import scipy\n","\n","  a = 1.0 * np.array(data)\n","  n = len(a)\n","  m = np.mean(a,axis=0)\n","  if m is None:\n","    m = np.nanmean(a,axis=0)\n","    print('There are missing values.')\n","  se = scipy.stats.sem(a,axis=0)\n","  ci = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n","\n","  if error=='SEM':\n","    e = se\n","  if error=='CI':\n","    e = ci\n","  \n","  return m, e"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-buDFD0FPh3x"},"source":["### Plot example\n"]},{"cell_type":"code","metadata":{"id":"h8tdKho4PlE6"},"source":["def plot_example(dFF,time_,events=None,dFF1=None,dFF2=None,measurement=None,time_m=None,\n","                 color='purple',ylim=None,yticks=None,ylabel=None,xticks=None,\n","                 color1='blue',ylim1=None,yticks1=None,ylabel1=None,\n","                 color2='red',ylim2=None,yticks2=None,ylabel2=None,\n","                 color_m='magenta',ylim_m=None,yticks_m=None,\n","                 color_e='red',\n","                 figsize=(5,3),save=False,imgname='example.pdf'):\n","\n","  fig = plt.figure(figsize=figsize)\n","  sns.set(style='ticks')\n","\n","  if measurement is not None:\n","    from matplotlib import gridspec\n","    gs = gridspec.GridSpec(2,1, height_ratios=[1,3])\n","      \n","    ax_m = fig.add_subplot(gs[0])\n","    sns.lineplot(x=time_m,y=measurement,color=color_m)\n","\n","    ax_m.set_xticks([])\n","    make_patch_spines_invisible(ax_m)\n","    ax_m.spines['right'].set_visible(True)\n","    ax_m.yaxis.set_ticks_position('right')\n","    ax_m.yaxis.set_label_position('right')\n","\n","    ax_m.spines['right'].set_color('magenta')\n","    ax_m.set_ylabel('Mobility\\n score',color=color_m)\n","    ax_m.tick_params(axis='y', colors=color_m)\n","\n","    ax_m.set_xlim(time_m[0], time_m[-1])\n","    if ylim_m is not None:\n","      ax_m.set_ylim(ylim_m)\n","    if yticks_m is not None:\n","      ax_m.set_yticks(yticks_m)\n","\n","    ax = fig.add_subplot(gs[1])\n","\n","  else:\n","    ax = fig.add_subplot()\n","\n","  sns.lineplot(x=time_,y=dFF,color=color,ax=ax)\n","\n","  if events is not None:\n","    if events.shape[1]==1:\n","      for e0 in events:\n","        ax.axvline(e0,linestyle='--',color='black')\n","    elif events.shape[1]==2:\n","      for e0,e1 in events:\n","        ax.axvspan(e0,e1,color=color_e,alpha=0.3)\n","\n","  ax.spines['top'].set_visible(False)\n","  ax.spines['right'].set_visible(False)\n","\n","  ax.spines['left'].set_color(color)\n","  ax.yaxis.label.set_color(color)\n","  ax.tick_params(axis='y',colors=color)\n","\n","  ax.set_xlabel('Time (s)',fontsize='large')\n","  ax.set_ylabel('z dF/F',fontsize='large',color='black')\n","\n","  ax.set_xlim(time_[0],time_[-1])\n","  if xticks is not None:\n","    ax.set_xticks(xticks)\n","  if ylim is not None:\n","    ax.set_ylim(ylim)\n","  if yticks is not None:\n","    ax.set_yticks(yticks)\n","  if ylabel is not None:\n","    ax.set_ylabel(ylabel,fontsize='large',color=color)\n","\n","  if dFF1 is not None:\n","    ax1 = ax.twinx()\n","    sns.lineplot(x=time_,y=dFF1,color=color1,ax=ax1)\n","\n","    if ylim1 is not None:\n","      ax1.set_ylim(ylim1)\n","    if yticks1 is not None:\n","      ax1.set_yticks(yticks1)\n","    if ylabel1 is not None:\n","      ax1.set_ylabel(ylabel1,fontsize='large',color=color1)\n","\n","    make_patch_spines_invisible(ax1)\n","    ax1.spines['right'].set_visible(True)\n","\n","    ax1.spines['right'].set_color(color1)\n","    ax1.yaxis.label.set_color(color1)\n","    ax1.tick_params(axis='y',colors=color1)\n","\n","\n","  if dFF2 is not None:\n","    ax2 = ax.twinx()  \n","    sns.lineplot(x=time_,y=dFF2,color=color2,ax=ax2)\n","\n","    if ylim2 is not None:\n","      ax2.set_ylim(ylim2)\n","    if yticks2 is not None:\n","      ax2.set_yticks(yticks2)\n","    if ylabel2 is not None:\n","      ax2.set_ylabel(ylabel2,fontsize='large' ,color=color2)\n","\n","    fig.subplots_adjust(right=0.9)\n","    ax2.spines['right'].set_position(('axes',1.15))\n","\n","    make_patch_spines_invisible(ax2)\n","    ax2.spines['right'].set_visible(True)\n","\n","    ax2.spines['right'].set_color(color2)\n","    ax2.yaxis.label.set_color(color2)\n","    ax2.tick_params(axis='y', colors=color2)\n","\n","  plt.tight_layout()\n","\n","\n","  if save:\n","    fig.savefig(imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QIMMZUP3-RaN"},"source":["### Plot perievent correlation"]},{"cell_type":"code","metadata":{"id":"Byb5rHJTWaRE"},"source":["def plot_perievent_correlation_counts(mean,sem,labels,figsize=(3,3),\n","                                      save=False,imgname='correlationCounts.pdf'):\n","\n","  import seaborn as sns\n","\n","  bottom = np.add(mean[0], mean[1])\n","  n = mean.shape[1]\n","\n","  sns.set(style=\"ticks\")\n","  fig = plt.figure(figsize=figsize)\n","  ax = fig.add_subplot()\n","  ax.bar(range(n),mean[2],yerr=[np.zeros(n),sem[2]],color='grey',edgecolor='grey',ecolor='grey',bottom=bottom)\n","  ax.bar(range(n),mean[1],yerr=[np.zeros(n),sem[1]],color='red',edgecolor='red',ecolor='red',bottom=mean[0])\n","  ax.bar(range(n),mean[0],yerr=[np.zeros(n),sem[0]],color='green',edgecolor='green',ecolor='green')\n","  ax.set_yticks([0.25, 0.5, 0.75, 1])\n","  ax.set_yticklabels(['25%', '50%', '75%', '100%'])\n","  ax.set_xticks(range(n))\n","  ax.set_xticklabels(labels,rotation=30,ha='right')\n","  sns.despine()\n","  plt.tight_layout()\n","\n","  if save:\n","    fig.savefig(imgname)\n","\n","  return fig"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QSym_oP31PBm"},"source":["### Plot cross-correlation"]},{"cell_type":"code","metadata":{"id":"DJmEU9AjdzgQ"},"source":["def plot_crosscorrelation(lags,corr,plot_type='mean and SEM',\n","                          color='green',ylim=None,xlim=None,yticks=None,xticks=None,\n","                          ylim1=None,yticks1=None,\n","                          figsize=(4,2),save=False,imgname='cross-correlation.pdf'):\n","  \n","  from matplotlib import gridspec\n","\n","  maxlag = np.zeros(len(corr))\n","  for i in range(len(corr)):\n","    sm_corr = list(smooth_signal(corr[i],5))\n","    maxlag[i] = get_midline(lags,sm_corr)\n","    \n","  #print(maxlag)\n","\n","  sns.set(style=\"ticks\")\n","  fig = plt.figure(figsize=figsize)\n","  gs = gridspec.GridSpec(1, 2, width_ratios=[5, 1])\n","  ax = fig.add_subplot(gs[0])\n","\n","  if plot_type=='individual traces':\n","    for mouse in range(corr.shape[0]):\n","      sns.lineplot(lags,corr[mouse],color=color)\n","  if plot_type=='mean and SEM':\n","    mean,error = calculate_mean_error(corr)\n","    ax.plot(lags,mean,color=color)\n","    ax.fill_between(lags,mean-error,mean+error,alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","  if plot_type=='mean and CI':\n","    mean,error = calculate_mean_error(corr,error='CI')\n","    ax.plot(lags,mean,color=color)\n","    ax.fill_between(lags,mean-error,mean+error,alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","\n","  ax.axvline(0,linestyle='--',color='black')\n","  if ylim is not None:\n","    ax.set_ylim(ylim)\n","  if xlim is not None:\n","    ax.set_xlim(xlim)\n","  if yticks is not None:\n","    ax.set_yticks(yticks)\n","  if xticks is not None:\n","    ax.set_xticks(xticks)\n","  ax.set_xlabel('lags (s)',size='large')\n","  ax.set_ylabel('correlation',size='large')\n","\n","  ax1 = fig.add_subplot(gs[1])\n","  if plot_type=='individual traces':\n","    ax1.plot(np.ones(len(maxlag)),maxlag,'o',color=color)\n","  if plot_type=='mean and SEM':\n","    m_maxlag,e_maxlag = calculate_mean_error(maxlag)\n","    ax1.errorbar(1,m_maxlag,e_maxlag,color=color)\n","    ax1.plot(1,m_maxlag,'o',color=color)\n","  if plot_type=='mean and CI':\n","    m_maxlag,e_maxlag = calculate_mean_error(maxlag,error='CI')\n","    ax1.errorbar(1,m_maxlag,e_maxlag,color=color)\n","    ax1.plot(1,m_maxlag,'o',color=color)\n","  ax1.set_ylabel('max lag (s)',size='large')\n","  ax1.set_xticks([])\n","  ax1.spines['bottom'].set_visible(False)\n","  ax1.axhline(0,color='black')\n","  if ylim1 is not None:\n","    ax1.set_ylim(ylim1)\n","  if yticks1 is not None:\n","    ax1.set_yticks(yticks1)\n","\n","  sns.despine()\n","  plt.tight_layout()\n","\n","  if save==True:\n","    fig.savefig(imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX-ybb0TAauB"},"source":["def get_midline(x,y):\n","\n","  total_sum = 0\n","  for i in range(len(x)-1):\n","    total_sum += y[i]*(x[i+1]-x[i])\n","\n","  left_sum=0\n","  i = 0\n","  while i<len(y)-1:\n","    left_sum += y[i]*(x[i+1]-x[i])\n","    if left_sum > total_sum/2:\n","      if (left_sum - total_sum/2) < (total_sum/2 - left_sum-y[i]*(x[i+1]-x[i])):\n","        middle = i\n","      else:\n","        middle = i-1\n","      break\n","    i+=1\n","  return x[middle]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPYGqroK1lpF"},"source":["# def plot_crosscorrelation(lags,corr,plot_type='mean and SEM',\n","#                           color='green',ylim=None,xlim=None,yticks=None,xticks=None,\n","#                           figsize=(3,2),save=False,imgname='cross-correlation.pdf'):\n","  \n","#   sns.set(style=\"ticks\")\n","#   fig = plt.figure(figsize=figsize)\n","#   ax = fig.add_subplot()\n","\n","#   if plot_type=='individual traces':\n","#     for mouse in range(corr.shape[0]):\n","#       sns.lineplot(lags,corr[mouse],color=color)\n","#   if plot_type=='mean and SEM':\n","#     mean,error = calculate_mean_error(corr)\n","#     ax.plot(lags,mean,color=color)\n","#     ax.fill_between(lags,mean-error,mean+error,alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","#   if plot_type=='mean and CI':\n","#     mean,error = calculate_mean_error(corr,error='CI')\n","#     ax.plot(lags,mean,color=color)\n","#     ax.fill_between(lags,mean-error,mean+error,alpha=0.3,edgecolor=color,facecolor=color,linewidth=0)\n","\n","#   ax.axvline(0,linestyle='--',color='black')\n","#   if ylim is not None:\n","#     ax.set_ylim(ylim)\n","#   if xlim is not None:\n","#     ax.set_xlim(xlim)\n","#   if yticks is not None:\n","#     ax.set_yticks(yticks)\n","#   if xticks is not None:\n","#     ax.set_xticks(xticks)\n","#   ax.set_xlabel('lags (s)')\n","#   ax.set_ylabel('correlation')\n","#   sns.despine()\n","#   plt.tight_layout()\n","\n","#   if save==True:\n","#     fig.savefig(imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0iJmpxgADbJ"},"source":["### Plot measures over tests"]},{"cell_type":"code","metadata":{"id":"5nVjEW5nrBkb"},"source":["def plot_boxplot(groups,values,color='green',ylabel=None,ylim=None,yticks=None,\n","                 figsize=(3,3),save=False,imgname='boxplot.pdf'):\n","  \n","  sns.set(style=\"ticks\")\n","  fig = plt.figure(figsize=figsize)\n","  ax = fig.add_subplot()\n","  sns.boxplot(groups,values,color=color)\n","  sns.swarmplot(groups,values,color='black')\n","  if ylabel is not None:\n","    ax.set_ylabel(ylabel)\n","  if ylim is not None:\n","    ax.set_ylim(ylim)\n","  if yticks is not None:\n","    ax.set_yticks(yticks)\n","  sns.despine()\n","  plt.tight_layout()\n","\n","  if save==True:\n","    fig.savefig(imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vLhs5teIDF08"},"source":["def plot_violinplot(groups,values,color='green',ylabel=None,ylim=None,yticks=None,\n","                 figsize=(3,3),save=False,imgname='boxplot.pdf'):\n","  \n","  sns.set(style=\"ticks\")\n","  fig = plt.figure(figsize=figsize)\n","  ax = fig.add_subplot()\n","  sns.violinplot(x=groups,y=values,color=color)\n","  #sns.swarmplot(groups,values,color='black')\n","  if ylabel is not None:\n","    ax.set_ylabel(ylabel)\n","  if ylim is not None:\n","    ax.set_ylim(ylim)\n","  if yticks is not None:\n","    ax.set_yticks(yticks)\n","  sns.despine()\n","  plt.tight_layout()\n","\n","  if save==True:\n","    fig.savefig(imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjAjg96synxw"},"source":["### Plot 3 phases"]},{"cell_type":"code","metadata":{"id":"6z7mGFMI_cme"},"source":["def plot_3phases(green_signal,red_signal,\n","                 figtitle,figsize=(24,13),\n","                 save=False,save_path='./figures/',image_format='.pdf'):  \n","  \n","  fig, axs = plt.subplots(3,2,figsize=figsize)\n","  axs = axs.ravel()\n","\n","  for i,key in enumerate(green_signal):\n","    axs[2*i].plot(green_signal[key],color='green')\n","    axs[2*i+1].plot(red_signal[key],color='red')\n","    axs[2*i].set_ylabel(key,fontsize='x-large')\n","  axs[4].set_xlabel('time', fontsize='x-large', multialignment='center')\n","  axs[5].set_xlabel('time', fontsize='x-large', multialignment='center')\n","  \n"," # Title\n","  if figtitle is not None:\n","    fig.suptitle(figtitle, fontsize='xx-large')\n","    \n"," # Save figure\n","  if save:\n","    imgname = figtitle.replace(' ','_') + '_raw3phases' + image_format\n","    fig.savefig(save_path+imgname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GKC4oLOHPnYq"},"source":["# Correlation analysis"]},{"cell_type":"markdown","metadata":{"id":"-U6jBI8Zpj64"},"source":["### Cross-correlation"]},{"cell_type":"code","metadata":{"id":"wAB8JGX4po7H"},"source":["def xcorr(x, y, normed=True, detrend=False, maxlags=10):\n","  \"\"\"\n","  Cross correlation of two signals of equal length\n","  Returns the coefficients when normed=True\n","  Returns inner products when normed=False\n","  Usage: lags, c = xcorr(x,y,maxlags=len(x)-1)\n","  Optional detrending e.g. mlab.detrend_mean\n","  \"\"\"    \n","\n","  Nx = len(x)\n","  if Nx != len(y):\n","      raise ValueError('x and y must be equal length')\n","\n","  if detrend:\n","      import matplotlib.mlab as mlab\n","      x = mlab.detrend_mean(np.asarray(x)) # can set your preferences here\n","      y = mlab.detrend_mean(np.asarray(y))\n","\n","  c = np.correlate(x, y, mode='full')\n","\n","  if normed:\n","      n = np.sqrt(np.dot(x, x) * np.dot(y, y)) # this is the transformation function\n","      c = np.true_divide(c,n)\n","\n","  if maxlags is None:\n","      maxlags = Nx - 1\n","\n","  if maxlags >= Nx or maxlags < 1:\n","      raise ValueError('maglags must be None or strictly '\n","                       'positive < %d' % Nx)\n","\n","  lags = np.arange(-maxlags, maxlags + 1)\n","  c = c[Nx - 1 - maxlags:Nx + maxlags]\n","  return lags, c"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DuyOMytDrCjz"},"source":["### Random sampling"]},{"cell_type":"code","metadata":{"id":"svWbIV-_rJvM"},"source":["import random\n","\n","def random_subset( iterator, K, seed=30 ):\n","\n","    random.seed(seed)\n","\n","    result = []\n","    N = 0\n","\n","    for item in iterator:\n","        N += 1\n","        if len( result ) < K:\n","            result.append( item )\n","        else:\n","            s = int(random.random() * N)\n","            if s < K:\n","                result[ s ] = item\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3k3WcshtEal"},"source":["# Print done"]},{"cell_type":"code","metadata":{"id":"UUCaM-HBtG4k","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595468522407,"user_tz":240,"elapsed":1029,"user":{"displayName":"Lab Proulx","photoUrl":"","userId":"11943260015308719679"}},"outputId":"46a174d8-87d6-4875-d151-6bf9b68aff25"},"source":["print('All Fiber Photometry functions are ready to use')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["All Fiber Photometry functions are ready to use\n"],"name":"stdout"}]}]}
